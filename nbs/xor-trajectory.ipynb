{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Trajectory when learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Aside: Should do [Working efficiently with jupyter lab](https://florianwilhelm.info/2018/11/working_efficiently_with_jupyter_lab/)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer\n",
    "from nnbench import NNBench\n",
    "from nnvis import NNVis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Build our `xor` net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffineLayer(2,2))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "net.extend(AffineLayer(2,1))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a test bench and a visualizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench = NNBench(net)\n",
    "vis = NNVis(bench)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare fixed training data for the learning process _[improve]_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = \\\n",
    "[(np.array([-1,-1]), np.array([-1])),\n",
    " (np.array([-1,1]), np.array([1])),\n",
    " (np.array([1,1]), np.array([-1])),\n",
    " (np.array([1,-1]), np.array([1]))]\n",
    "dc = 0\n",
    "amp= 1\n",
    "temp = [(d[0]*amp/2+dc,d[1]*amp/2+dc) for d in dat]\n",
    "\n",
    "bench.training_data = ((np.array([v[0] for v in temp]),\n",
    "                        np.array([v[1] for v in temp])),)\n",
    "bench.training_data_gen = bench.training_data_gen_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the state to an ordinary example starting point, for consistent notebook behavior below. We also make it the checkpoint in the bench."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.set_state_from_vector(np.array([-0.88681521, -1.28596788,  0.3248974 , -2.33838503,  0.34761944,\n",
    "       -0.94541789,  1.99448043,  0.38704839, -3.8844268 ]))\n",
    "bench.checkpoint_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The track that learning takes\n",
    "Let us examine the trajectory in state space during learning, and the loss function.\n",
    "Each learning iteration changes the net state. We can examine those deltas.\n",
    "Questions:\n",
    "1. Are there regimes of direction-of-change (DoC) in state space, or does the DoC wander chaotically?\n",
    "1. What are the spectral characteristics of the DoC? Length characteristics?\n",
    "1. How do the DoC characteristics relate to the loss function, and it's first difference?\n",
    "1. How do these trajectories vary with learning rate? Are there clues in these to adapt the learning rate?\n",
    "1. How do the trajectory characteristics vary across different starting nets?\n",
    "1. How do these measures vary with the objective function of the learning process, that is, what you're trying to teach the net?\n",
    "1. How do the different layers with learning state evolve? Do they settle at different times? How does an upstream layer change, as a consequence of learning, affect downstream layers? Down affect up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.rollback_net()\n",
    "#bench.net.eta = 0.25\n",
    "bench.net.eta = 0.4101\n",
    "learned_track = bench.learn_track(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the angles between trajectory steps, from\n",
    "$$\\mathbf {a} \\cdot \\mathbf {b} = \\left\\|\\mathbf {a} \\right\\|\\left\\|\\mathbf {b} \\right\\|\\cos \\theta \\\\\n",
    "\\cos \\theta = \\frac{\\mathbf {a} \\cdot \\mathbf {b}}{\\left\\|\\mathbf {a} \\right\\|\\left\\|\\mathbf {b} \\right\\|} \\\\\n",
    "$$\n",
    "where $\\mathbf {a}$ and $\\mathbf {b}$ are a state-space trajectory step and the succeeding step respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traja = bench.analyze_learning_track(learned_track)\n",
    "vis.plot_trajectory(traja)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "We asked:\n",
    "1. Are there regimes of direction-of-change (DoC) in state space, or does the DoC wander chaotically? \\\n",
    "    _**Answer:** Regimes exist. Often the initial direction is maintained (cos near 1) up to some region where the\n",
    "    direction becomes chaotic, the loss improves, then falls into back-and-forth oscillations (cos near 0)\n",
    "    perfecting the loss._\n",
    "1. What are the spectral characteristics of the DoC? Length characteristics?\n",
    "1. How do the DoC characteristics relate to the loss function, and it's first difference?\n",
    "1. How do these trajectories vary with learning rate? Are there clues in these to adapt the learning rate?\n",
    "1. How do the trajectory characteristics vary across different starting nets?\n",
    "1. How do these measures vary with the objective function of the learning process, that is, what you're trying to teach the net?\n",
    "1. How do the different layers with learning state evolve? Do they settle at different times? How does an upstream layer change, as a consequence of learning, affect downstream layers? Down affect up?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Stop notebook execution here if entering from above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.randomize_net()\n",
    "t = bench.learn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.net.state_vector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = bench.net\n",
    "net([[-.5, -.5], [-.5, .5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nnbench import Thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Thing(color='brown', weight=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cow = 'moo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.cow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boneyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Stop notebook execution, the rest is scrap\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrangle the state-space trajectory and the losses into form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = np.vstack([v[0] for v in lt])\n",
    "losses = np.vstack([v[1] for v in lt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take first differences, which represent the changes at each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_steps = np.diff(trajectory, axis=0)\n",
    "loss_steps = np.diff(losses, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_steps[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the L2 norm of the trajectory steps $\\lVert traj \\rVert$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_L2 = np.sqrt(np.einsum('...i,...i', traj_steps, traj_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_L2), traj_L2[:5], traj_L2[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the angles between trajectory steps, from\n",
    "$$\\mathbf {a} \\cdot \\mathbf {b} = \\left\\|\\mathbf {a} \\right\\|\\left\\|\\mathbf {b} \\right\\|\\cos \\theta \\\\\n",
    "\\cos \\theta = \\frac{\\mathbf {a} \\cdot \\mathbf {b}}{\\left\\|\\mathbf {a} \\right\\|\\left\\|\\mathbf {b} \\right\\|} \\\\\n",
    "$$\n",
    "where $\\mathbf {a}$ and $\\mathbf {b}$ are a state-space trajectory step and the succeeding step respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $\\mathbf {a} \\cdot \\mathbf {b}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajn_dot_nplus1 = np.einsum('...i,...i', traj_steps[:-1], traj_steps[1:])\n",
    "trajn_dot_nplus1[:5], np.any(trajn_dot_nplus1 < 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $\\left\\|\\mathbf {a} \\right\\|\\left\\|\\mathbf {b} \\right\\|$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cos_denom = np.multiply(traj_L2[:-1], traj_L2[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will be the divisor. Some entries may be zero, so we adapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj_L2) - np.count_nonzero(traj_L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.equal(traj_L2, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find $\\cos \\theta$ by dividing, excluding division by zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cos = np.divide(trajn_dot_nplus1, traj_cos_denom, where=traj_cos_denom!=0.0)\n",
    "traj_cos[:5], traj_cos[-5:], min(traj_cos), max(traj_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traj_theta = np.arccos(traj_cos)\n",
    "#traj_theta[:5], traj_theta[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffineLayer(2,2))\n",
    "#leak = 0\n",
    "#net.extend(MapLayer(lambda x: (x*(1+leak/2)+abs(x)*(1-leak/2))/2, lambda d: [leak,1][1 if d>0 else 0]))\n",
    "#net.extend(MapLayer(lambda x: max(0, np.sign(x)) * x, lambda d: max(0, np.sign(d))))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "net.extend(AffineLayer(2,1))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "#sigmoid = lambda x: 1/(np.exp(x)+1)\n",
    "#net.extend(MapLayer(sigmoid, lambda d: sigmoid(d)*(1-sigmoid(d))))\n",
    "#net.extend(MapLayer(lambda x: max(0, np.sign(x)) * x, lambda d: max(0, np.sign(d))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
