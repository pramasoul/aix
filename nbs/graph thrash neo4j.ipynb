{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dedicated-potential",
   "metadata": {},
   "source": [
    "# Graph thrash `neo4j`\n",
    "Train a net, recording its path in `neo4j` graph database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-smart",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "discrete-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "piano-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "steady-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from hashlib import sha256\n",
    "from pprint import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-beatles",
   "metadata": {},
   "source": [
    "## Connecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-dining",
   "metadata": {},
   "source": [
    "Need to get the `gpu-jupyter` and the `neo4j` docker containers connected. If run bare, something like:\n",
    "\n",
    "    docker network connect gpu-jupyter_default gpu-jupyter \n",
    "    docker network connect gpu-jupyter_default neo4j\n",
    "    docker network inspect gpu-jupyter_default \n",
    "    \n",
    "Docker has better ways than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "academic-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = neo4j.GraphDatabase.driver(\"neo4j://172.19.0.2:7687\", auth=(\"neo4j\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hearing-astrology",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b734c674563a>:1: ExperimentalWarning: The configuration may change in the future.\n",
      "  driver.verify_connectivity()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{IPv4Address(('172.19.0.2', 7687)): [{'ttl': 300,\n",
       "   'servers': [{'addresses': ['172.19.0.2:7687'], 'role': 'WRITE'},\n",
       "    {'addresses': ['172.19.0.2:7687'], 'role': 'READ'},\n",
       "    {'addresses': ['172.19.0.2:7687'], 'role': 'ROUTE'}]}]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outside-state",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boring-least",
   "metadata": {},
   "source": [
    "## `numpy` array store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "israeli-sauce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils_neo4j import NumpyStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "agreed-advisory",
   "metadata": {},
   "source": [
    "# The Model\n",
    "    Investigation -> Experiment -> multiple ResultDAGs\n",
    "`ResultDAG` is\n",
    "\n",
    "    (netState, params)-[mutation]->(netState, params)-[mutation ...\n",
    "                     +-[mutation]->(netstate, params) ...\n",
    "etc. `mutation` can be a learning trajectory, or an edit.\n",
    "\n",
    "Perhaps `mutation` can be expressed in python.\n",
    "\n",
    "Generally the results of experiments are preferred to be reproducible, but they won't always be, when they import entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-tracker",
   "metadata": {},
   "source": [
    "## Some neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "swedish-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer\n",
    "from nnbench import NetMaker, NNMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "superior-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm = NetMaker(NNMEG)\n",
    "xor_net = mnm('2x2tx1t')\n",
    "adc_net = mnm('1x8tx8tx3t')\n",
    "#adc_net = mnm('1x8tx8tx3tx3t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-values",
   "metadata": {},
   "source": [
    "## ... and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "genetic-concrete",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_training_batch = (np.array([[-0.5, -0.5],\n",
    "                            [-0.5,  0.5],\n",
    "                            [ 0.5,  0.5],\n",
    "                            [ 0.5, -0.5]]),\n",
    "                  np.array([[-0.5],\n",
    "                            [ 0.5],\n",
    "                            [-0.5],\n",
    "                            [ 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "institutional-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adc(input):\n",
    "    m = max(0, min(7, int(8*input)))\n",
    "    return np.array([(m>>2)&1, (m>>1)&1, m&1]) * 2 - 1\n",
    "\n",
    "vadc = lambda v: np.array([adc(p) for p in v])\n",
    "#plot_ADC(vadc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "skilled-alfred",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 1, 1.0/(8*8)).reshape(-1,1) # 1 point in each output region\n",
    "adc_training_batch = (x, vadc(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-malta",
   "metadata": {},
   "source": [
    "### We use `adc_net`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "painted-jaguar",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = adc_net\n",
    "training_batch = adc_training_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-convergence",
   "metadata": {},
   "source": [
    "# The graph database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-outside",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjustable-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps = NumpyStore(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "latest-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_start(tx, facts, net):\n",
    "    tx.run(\"MERGE (:net \"\n",
    "           \"{shorthand: $shorthand, \"\n",
    "           \"ksv: $ksv, \"\n",
    "           \"loss: $loss, \"\n",
    "           \"ts: $ts, \"\n",
    "           \"experiment: $experiment, \"\n",
    "           \"head: $head}) \",\n",
    "           **facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solid-partnership",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subsequent(tx, facts, net):\n",
    "    tx.run(\"MATCH (a:net {ksv: $prior_ksv}) \"\n",
    "           \"MERGE (a)-\"\n",
    "           \"[:LEARNED \"\n",
    "               \"{batch_points: $batch_points, \"\n",
    "               \"etas: $etas, \"\n",
    "               \"eta_change_batches: $eta_change_batches, \"\n",
    "               \"batches_this_segment: $batches_this_segment, \"\n",
    "               \"losses: $loss, \"\n",
    "               \"loss_steps: $loss_step, \"\n",
    "               \"traj_L2_sqs: $traj_L2_sq, \"\n",
    "               \"traj_cos_sq_signeds: $traj_cos_sq_signed, \"\n",
    "               \"ts: $ts \"\n",
    "               \"}]->\"\n",
    "           \"(b:net \"\n",
    "               \"{shorthand: $shorthand, \"\n",
    "               \"ksv: $ksv, \"\n",
    "               \"loss: $end_loss, \"\n",
    "               \"ts: $ts, \"\n",
    "               \"experiment: $experiment}) \",\n",
    "           **facts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-satellite",
   "metadata": {},
   "source": [
    "## An example experiment's DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-apparatus",
   "metadata": {},
   "source": [
    "### We use `adc_net`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adjusted-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = adc_net\n",
    "training_batch = adc_training_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cleared-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eta = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "existing-rubber",
   "metadata": {},
   "source": [
    "## Train, recording trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "external-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(net):\n",
    "    loss = net.losses([training_batch])[0]\n",
    "    prior_ksv \n",
    "    batch_ctr = 0\n",
    "    while loss > 1e-3:\n",
    "        batch_ctr_at_seg_start = batch_ctr\n",
    "        losses = []\n",
    "        etas = []\n",
    "        deltas = []\n",
    "        prior_loss = loss\n",
    "        while loss / prior_loss > 0.7071 and len(deltas) < 100:\n",
    "            if not etas or net.eta != etas[-1][1]:\n",
    "                etas.append([batch_ctr, net.eta])\n",
    "            loss = net.learn([training_batch])\n",
    "            if batch_ctr < 100 or batch_ctr % 100 == 0:\n",
    "                losses.append([batch_ctr, loss])\n",
    "                deltas.append([batch_ctr, net.deltas()])\n",
    "            batch_ctr += 1\n",
    "        #if losses[-1][0] < (batch_ctr-1):\n",
    "        #    losses.append([batch_ctr, loss])\n",
    "        if not deltas or deltas[-1][0] < (batch_ctr-1):\n",
    "            deltas.append((batch_ctr, net.deltas()))\n",
    "        properties = dict(zip(deltas[0][1]._fields, map(list, (zip(*(v[1] for v in deltas)))))) # RedisGraph has a tuple allergy\n",
    "        #properties = {}\n",
    "        properties['batch_points'] = [v[0] for v in deltas]\n",
    "        #properties['etas'] = etas\n",
    "        properties['etas'], properties['eta_change_batches'] = (list(v) for v in zip(*etas))\n",
    "        properties['batches_this_segment'] = batch_ctr - batch_ctr_at_seg_start\n",
    "        properties['ts'] = time.time()\n",
    "        properties['shorthand'] = net.shorthand\n",
    "        properties['ksv'] = nps.store(net.state_vector())\n",
    "        properties['end_loss'] = net.losses([training_batch])[0]\n",
    "        properties['experiment'] = 'ADC'\n",
    "        yield properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "trained-airport",
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_facts = {'shorthand': net.shorthand,\n",
    "              'ksv': nps.store(net.state_vector()),\n",
    "              'loss': net.losses([training_batch])[0],\n",
    "              'ts': time.time(),\n",
    "              'experiment': 'ADC',\n",
    "              'head': True,\n",
    "             }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggregate-chapel",
   "metadata": {},
   "source": [
    "### Record results as they arrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impaired-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.write_transaction(add_start, starting_facts, net)\n",
    "    prior_ksv = starting_facts['ksv']\n",
    "    for observations in trainer(net):\n",
    "        observations['prior_ksv'] = prior_ksv\n",
    "        prior_ksv = observations['ksv']\n",
    "        #pprint(observations)\n",
    "        #observations['etas'] = observations['etas'][0] #DEBUG HACK, FIXME\n",
    "        session.write_transaction(add_subsequent, observations, net)\n",
    "        print(f\"loss {observations['end_loss']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
