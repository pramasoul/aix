{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Nets t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "#%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Importing_Notebooks\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network built of components which:\n",
    "1. accept an ordered set of reals (we'll use `numpy.array`, and  call them vectors) at the input port and produce another at the output port - this is forward propagation. ${\\displaystyle f\\colon \\mathbf {R} ^{n}\\to \\mathbf {R} ^{m}}$\n",
    "1. accept an ordered set of reals at the output port, representing the gradient of the loss function at the output, and produce the gradient of the loss function at the input port - this is back propagation, aka backprop. ${\\displaystyle b\\colon \\mathbf {R} ^{m}\\to \\mathbf {R} ^{n}}$\n",
    "1. from the gradient of the loss function at the output, calculate the partial of the loss function w.r.t the internal parameters ${\\displaystyle \\frac{\\partial E}{\\partial w} }$\n",
    "1. accept a scalar $\\alpha$ to control the adjustment of internal parameters. _Or is this effected by scaling the loss gradient before passing??_\n",
    "1. update internal parameters ${\\displaystyle w \\leftarrow w - \\alpha \\frac{\\partial E}{\\partial w} }$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        \"\"\"Computes response to input\"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def backprop(self, output_delE):\n",
    "        \"\"\"Uses output error gradient to adjust internal parameters, and returns gradient of error at input\"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A network built of a cascade of layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "        self.alpha = 0.1 #FIXME\n",
    "        \n",
    "    def extend(self, net):\n",
    "        self.layers.append(net)\n",
    "        \n",
    "    def __call__(self, input):\n",
    "        v = input\n",
    "        for net in self.layers:\n",
    "            v = net(v)\n",
    "        return v\n",
    "    \n",
    "    def learn(self, facts):\n",
    "        for (x, expected) in facts:\n",
    "            y = self(x)\n",
    "            e = y - expected\n",
    "            loss = e.dot(e)/2.0\n",
    "            agrad = e * self.alpha\n",
    "            for net in reversed(self.layers):\n",
    "                agrad = net.backprop(agrad)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IdentityLayer(Layer):\n",
    "    def __call__(self, x):\n",
    "        return x\n",
    "    \n",
    "    def backprop(self, output_delE):\n",
    "        return output_delE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine\n",
    "A layer that does an [affine transformation](https://mathworld.wolfram.com/AffineTransformation.html) aka affinity, which is the classic fully-connected layer with output offsets.\n",
    "\n",
    "$$ \\mathbf{M} \\mathbf{x} + \\mathbf{b} = \\mathbf{y} $$\n",
    "where\n",
    "$$\n",
    "\\mathbf{x} = \\sum_{j=1}^{n} x_j \\mathbf{\\hat{x}}_j \\\\\n",
    "\\mathbf{b} = \\sum_{i=1}^{m} b_i \\mathbf{\\hat{y}}_i \\\\\n",
    "\\mathbf{y} = \\sum_{i=1}^{m} y_i \\mathbf{\\hat{y}}_i\n",
    "$$\n",
    "and $\\mathbf{M}$ can be written\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    m_{1,1} & \\dots & m_{1,n} \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    m_{m,1} & \\dots & m_{m,n}\n",
    "\\end{bmatrix} \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error gradient back-propagation\n",
    "$$ \n",
    "\\begin{align}\n",
    " \\frac{\\partial loss}{\\partial\\mathbf{x}}\n",
    "  = \\frac{\\partial loss}{\\partial\\mathbf{y}} \\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{x}}\n",
    "  = \\mathbf{M}\\frac{\\partial loss}{\\partial\\mathbf{y}}\n",
    "\\end{align}\n",
    "$$\n",
    "_SOLVE: Left-multiply or right-multiply?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter adjustment\n",
    "$$\n",
    " \\frac{\\partial loss}{\\partial\\mathbf{M}}\n",
    " = \\frac{\\partial loss}{\\partial\\mathbf{y}} \\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{M}}\n",
    " = \\frac{\\partial loss}{\\partial\\mathbf{y}} \\mathbf{x} \\\\\n",
    " \\frac{\\partial loss}{\\partial\\mathbf{b}}\n",
    " = \\frac{\\partial loss}{\\partial\\mathbf{y}} \\frac{\\partial\\mathbf{y}}{\\partial\\mathbf{b}}\n",
    " = \\frac{\\partial loss}{\\partial\\mathbf{y}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffinityLayer(Layer):\n",
    "    \"\"\"An affine transformation, which is the classic fully-connected layer with offsets\"\"\"\n",
    "    def __init__(self, n, m):\n",
    "        self.M = np.empty((m, n))\n",
    "        self.b = np.empty(m)\n",
    "        self.randomize()\n",
    "        \n",
    "    def randomize(self):\n",
    "        self.M[:] = np.random.randn(*self.M.shape)\n",
    "        self.b[:] = np.random.randn(*self.b.shape)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.input = x\n",
    "        self.output = self.M @ x + self.b\n",
    "        return self.output\n",
    "    \n",
    "    def backprop(self, output_delE):\n",
    "        input_delE = self.M @ output_delE\n",
    "        self.M -= np.einsum('i,j', output_delE, self.input) # use np.outer?\n",
    "        self.b -= output_delE\n",
    "        return input_delE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map\n",
    "Maps a scalar function on the inputs, for e.g. activation layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MapLayer(Layer):\n",
    "    \"\"\"Map a scalar function on the input taken element-wise\"\"\"\n",
    "    def __init__(self, fun, dfundx):\n",
    "        self.vfun = np.vectorize(fun)\n",
    "        self.vdfundx = np.vectorize(dfundx)\n",
    "\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        self.input = x\n",
    "        return self.vfun(x)\n",
    "    \n",
    "    def backprop(self, output_delE):\n",
    "        input_delE = self.vdfundx(self.input) * output_delE\n",
    "        return input_delE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One identity layer\n",
    "See if the wheels turn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "net.extend(IdentityLayer())\n",
    "all(net(np.arange(3)) == np.arange(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not learn, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts = [(np.arange(2*n, 2*n+2), np.arange(2*n+1, 2*n-1, -1)) for n in range(3)]\n",
    "net.learn(facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(np.arange(2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One map layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Network()\n",
    "net.extend(MapLayer(lambda x: x+1, lambda d: 1))\n",
    "all(net(np.arange(3)) == np.arange(3)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not learn, as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, True, array([3, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.learn(facts), all(net(np.arange(5)) == np.arange(5)+1), net(np.arange(2,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One affine layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffinityLayer(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.21533062,  0.28402263],\n",
       "        [-0.28379346, -1.35249073]]),\n",
       " array([ 0.61141609, -1.15769416]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = net.layers[0]\n",
    "t.M, t.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can it learn the identity transformation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nnbench import NNBench\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNBench:\n",
    "    def __init__(self, net, ideal=lambda x:x):\n",
    "        self.net = net\n",
    "        self.ideal = ideal\n",
    "        self.gc_protect = []\n",
    "        self.seed = 3\n",
    "    \n",
    "    def checkpoint_net(self):\n",
    "        self.net_checkpoint = dill.dumps(self.net)\n",
    "        \n",
    "    def rollback_net(self):\n",
    "        self.net = dill.loads(self.net_checkpoint)\n",
    "        \n",
    "    def training_data_gen(self, n):\n",
    "        \"\"\"Generate n instances of labelled training data\"\"\"\n",
    "        np.random.seed(self.seed)\n",
    "        for i in range(n):\n",
    "            v = np.random.randn(2)\n",
    "            yield (v, self.ideal(v))\n",
    "            \n",
    "    def learn(self, n=100):\n",
    "        return [self.net.learn([fact]) for fact in self.training_data_gen(n)]\n",
    "            \n",
    "    def learning_potential(self, n=100, alpha=None):\n",
    "        stash = dill.dumps(self.net)\n",
    "        if alpha is not None: # only change the net's alpha if a value was passed to us\n",
    "            self.net.alpha = alpha\n",
    "        loss = self.net.learn(fact for fact in self.training_data_gen(n))\n",
    "        self.net = dill.loads(stash)\n",
    "        return -np.log(loss)\n",
    "        \n",
    "    def plot_learning(self, n):\n",
    "        from matplotlib import pyplot as plt\n",
    "        # self.losses = losses = [self.net.learn(fact for fact in self.training_data_gen(n))]\n",
    "        losses = self.learn(n)\n",
    "        plt.yscale('log')\n",
    "        plt.plot(range(len(losses)),losses)\n",
    "        plt.show(block=0)\n",
    "        \n",
    "    def knobs_plot_learning(self, n):\n",
    "        # from matplotlib import pyplot as plt\n",
    "        fig, ax = plt.subplots()\n",
    "        plt.subplots_adjust(left=0.25, bottom=0.25)\n",
    "        a0 = 5\n",
    "        f0 = 3\n",
    "        \n",
    "        ###\n",
    "        losses = [self.net.learn([fact]) for fact in self.training_data_gen(n)]\n",
    "        l, = plt.plot(range(len(losses)), losses, lw=2)\n",
    "        ax.margins(x=0)\n",
    "        plt.yscale('log')\n",
    "\n",
    "        axcolor = 'lightgoldenrodyellow'\n",
    "        axfreq = plt.axes([0.25, 0.1, 0.65, 0.03], facecolor=axcolor)\n",
    "        axamp = plt.axes([0.25, 0.15, 0.65, 0.03], facecolor=axcolor)\n",
    "\n",
    "        sfreq = Slider(axfreq, '⍺', 0, 1, valinit=self.net.alpha)\n",
    "        samp = Slider(axamp, 'Num', 1, 1000, valinit=100, valstep=1)\n",
    "        \n",
    "        filtfunc = [lambda x:x]\n",
    "        \n",
    "        \n",
    "        big = max(losses)\n",
    "        ax.set_title(f\"maxloss:{big}\")\n",
    "    \n",
    "        iax = plt.axes([0.025, 0.7, 0.15, 0.15])\n",
    "        def make_iax_image():\n",
    "            return np.concatenate([np.concatenate((l.M,np.array([l.b])),axis=0)\n",
    "                                   for l in self.net.layers\n",
    "                                  if hasattr(l, 'M')],axis=1)\n",
    "        def update_iax(img=[iax.imshow(make_iax_image())]):\n",
    "            img[0].remove()\n",
    "            img[0] = iax.imshow(make_iax_image())\n",
    "\n",
    "        \n",
    "        \n",
    "        def update(val,ax=ax,loc=[l]):\n",
    "            n = int(samp.val)\n",
    "            self.rollback_net()\n",
    "            sfunc = lambda x: 2**(-1.005/(x+.005))\n",
    "            self.net.alpha = sfunc(sfreq.val)\n",
    "            #sfreq.set_label(\"2.4e\"%(self.net.alpha,))\n",
    "            losses = filtfunc[0]([self.net.learn([fact]) for fact in self.training_data_gen(n)])\n",
    "            big = max(losses)\n",
    "            ax.set_title(f\"⍺={self.net.alpha},max loss:{big}\")\n",
    "            loc[0].remove()\n",
    "            loc[0], = ax.plot(range(len(losses)), losses, lw=2,color='xkcd:blue')\n",
    "            ax.set_xlim((0,len(losses)))\n",
    "            ax.set_ylim((min(losses),big))\n",
    "            update_iax()\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        sfreq.on_changed(update)\n",
    "        samp.on_changed(update)\n",
    "\n",
    "        resetax = plt.axes([0.8, 0.025, 0.1, 0.04])\n",
    "        button = Button(resetax, 'Reset', color=axcolor, hovercolor='0.975')\n",
    "\n",
    "    \n",
    "        def reset(event):\n",
    "            self.seed += 1\n",
    "            update()\n",
    "        button.on_clicked(reset)\n",
    "\n",
    "        rax = plt.axes([0.025, 0.5, 0.15, 0.15], facecolor=axcolor)\n",
    "        radio = RadioButtons(rax, ('raw', 'low pass', 'green'), active=0)\n",
    "\n",
    "        \n",
    "        def colorfunc(label):\n",
    "            if label == \"raw\":\n",
    "                filtfunc[0] = lambda x:x\n",
    "            elif label == \"low pass\":\n",
    "                filtfunc[0] = lambda x:ndimage.gaussian_filter(np.array(x),3)\n",
    "            #l.set_color(label)\n",
    "            #fig.canvas.draw_idle()\n",
    "            update()\n",
    "        radio.on_clicked(colorfunc)\n",
    "\n",
    "        plt.show()\n",
    "        #return 'gc protect:', update, reset, colorfunc,sfreq,samp, radio, button\n",
    "        self.gc_protect.append((update, reset, colorfunc,sfreq,samp, radio, button))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench = NNBench(net)\n",
    "bench.checkpoint_net()\n",
    "bench.learning_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.plot_learning(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acd10e6f7bf4c36ab2d5692826bd8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bench.ideal = lambda v: np.array([v[1], v[0]])\n",
    "bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn thru a map layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This layer doubles its input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffinityLayer(2,2))\n",
    "\n",
    "def dtanh(x):\n",
    "    v = np.tanh(x)\n",
    "    return (1+v)*(1-v)\n",
    "\n",
    "net.extend(MapLayer(lambda x:x*x/2.0, lambda d:d))\n",
    "#net.extend(MapLayer(np.tanh, dtanh))\n",
    "bench = NNBench(net)\n",
    "bench.checkpoint_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.32158469,  0.15113037],\n",
       "        [-0.01862772,  0.48352879]]),\n",
       " array([0.76896516, 1.36624284]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].M, net.layers[0].b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in multiply\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in subtract\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.ideal = lambda v: [(v[0]-v[1])**2,0]\n",
    "#bench.ideal = lambda v: [(v[0]>0)*2-1,(v[0]>v[1])*2-1]\n",
    "bench.learning_potential()\n",
    "#bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "807b88706d7f4bde9645e6168e94892b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:13: RuntimeWarning: overflow encountered in multiply\n",
      "  del sys.path[0]\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in subtract\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in subtract\n"
     ]
    }
   ],
   "source": [
    "bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALLOW_THREADS',\n",
       " 'AxisError',\n",
       " 'BUFSIZE',\n",
       " 'CLIP',\n",
       " 'ComplexWarning',\n",
       " 'DataSource',\n",
       " 'ERR_CALL',\n",
       " 'ERR_DEFAULT',\n",
       " 'ERR_IGNORE',\n",
       " 'ERR_LOG',\n",
       " 'ERR_PRINT',\n",
       " 'ERR_RAISE',\n",
       " 'ERR_WARN',\n",
       " 'FLOATING_POINT_SUPPORT',\n",
       " 'FPE_DIVIDEBYZERO',\n",
       " 'FPE_INVALID',\n",
       " 'FPE_OVERFLOW',\n",
       " 'FPE_UNDERFLOW',\n",
       " 'False_',\n",
       " 'Inf',\n",
       " 'Infinity',\n",
       " 'LowLevelCallable',\n",
       " 'MAXDIMS',\n",
       " 'MAY_SHARE_BOUNDS',\n",
       " 'MAY_SHARE_EXACT',\n",
       " 'MachAr',\n",
       " 'ModuleDeprecationWarning',\n",
       " 'NAN',\n",
       " 'NINF',\n",
       " 'NZERO',\n",
       " 'NaN',\n",
       " 'PINF',\n",
       " 'PZERO',\n",
       " 'RAISE',\n",
       " 'RankWarning',\n",
       " 'SHIFT_DIVIDEBYZERO',\n",
       " 'SHIFT_INVALID',\n",
       " 'SHIFT_OVERFLOW',\n",
       " 'SHIFT_UNDERFLOW',\n",
       " 'ScalarType',\n",
       " 'TooHardError',\n",
       " 'True_',\n",
       " 'UFUNC_BUFSIZE_DEFAULT',\n",
       " 'UFUNC_PYVALS_NAME',\n",
       " 'VisibleDeprecationWarning',\n",
       " 'WRAP',\n",
       " '_UFUNC_API',\n",
       " '__SCIPY_SETUP__',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__config__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numpy_version__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " '_add_newdoc_ufunc',\n",
       " '_dep_fft',\n",
       " '_deprecated',\n",
       " '_distributor_init',\n",
       " '_fun',\n",
       " '_key',\n",
       " '_lib',\n",
       " '_msg',\n",
       " '_sci',\n",
       " 'absolute',\n",
       " 'absolute_import',\n",
       " 'add',\n",
       " 'add_docstring',\n",
       " 'add_newdoc',\n",
       " 'add_newdoc_ufunc',\n",
       " 'alen',\n",
       " 'all',\n",
       " 'allclose',\n",
       " 'alltrue',\n",
       " 'amax',\n",
       " 'amin',\n",
       " 'angle',\n",
       " 'any',\n",
       " 'append',\n",
       " 'apply_along_axis',\n",
       " 'apply_over_axes',\n",
       " 'arange',\n",
       " 'arccos',\n",
       " 'arccosh',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctan2',\n",
       " 'arctanh',\n",
       " 'argmax',\n",
       " 'argmin',\n",
       " 'argpartition',\n",
       " 'argsort',\n",
       " 'argwhere',\n",
       " 'around',\n",
       " 'array',\n",
       " 'array2string',\n",
       " 'array_equal',\n",
       " 'array_equiv',\n",
       " 'array_repr',\n",
       " 'array_split',\n",
       " 'array_str',\n",
       " 'asanyarray',\n",
       " 'asarray',\n",
       " 'asarray_chkfinite',\n",
       " 'ascontiguousarray',\n",
       " 'asfarray',\n",
       " 'asfortranarray',\n",
       " 'asmatrix',\n",
       " 'asscalar',\n",
       " 'atleast_1d',\n",
       " 'atleast_2d',\n",
       " 'atleast_3d',\n",
       " 'average',\n",
       " 'bartlett',\n",
       " 'base_repr',\n",
       " 'binary_repr',\n",
       " 'bincount',\n",
       " 'bitwise_and',\n",
       " 'bitwise_not',\n",
       " 'bitwise_or',\n",
       " 'bitwise_xor',\n",
       " 'blackman',\n",
       " 'block',\n",
       " 'bmat',\n",
       " 'bool8',\n",
       " 'bool_',\n",
       " 'broadcast',\n",
       " 'broadcast_arrays',\n",
       " 'broadcast_to',\n",
       " 'busday_count',\n",
       " 'busday_offset',\n",
       " 'busdaycalendar',\n",
       " 'byte',\n",
       " 'byte_bounds',\n",
       " 'bytes0',\n",
       " 'bytes_',\n",
       " 'c_',\n",
       " 'can_cast',\n",
       " 'cast',\n",
       " 'cbrt',\n",
       " 'cdouble',\n",
       " 'ceil',\n",
       " 'cfloat',\n",
       " 'char',\n",
       " 'character',\n",
       " 'chararray',\n",
       " 'choose',\n",
       " 'clip',\n",
       " 'clongdouble',\n",
       " 'clongfloat',\n",
       " 'column_stack',\n",
       " 'common_type',\n",
       " 'compare_chararrays',\n",
       " 'complex128',\n",
       " 'complex256',\n",
       " 'complex64',\n",
       " 'complex_',\n",
       " 'complexfloating',\n",
       " 'compress',\n",
       " 'concatenate',\n",
       " 'conj',\n",
       " 'conjugate',\n",
       " 'convolve',\n",
       " 'copy',\n",
       " 'copysign',\n",
       " 'copyto',\n",
       " 'corrcoef',\n",
       " 'correlate',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'count_nonzero',\n",
       " 'cov',\n",
       " 'cross',\n",
       " 'csingle',\n",
       " 'ctypeslib',\n",
       " 'cumprod',\n",
       " 'cumproduct',\n",
       " 'cumsum',\n",
       " 'datetime64',\n",
       " 'datetime_as_string',\n",
       " 'datetime_data',\n",
       " 'deg2rad',\n",
       " 'degrees',\n",
       " 'delete',\n",
       " 'deprecate',\n",
       " 'deprecate_with_doc',\n",
       " 'diag',\n",
       " 'diag_indices',\n",
       " 'diag_indices_from',\n",
       " 'diagflat',\n",
       " 'diagonal',\n",
       " 'diff',\n",
       " 'digitize',\n",
       " 'disp',\n",
       " 'divide',\n",
       " 'division',\n",
       " 'divmod',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'dsplit',\n",
       " 'dstack',\n",
       " 'dtype',\n",
       " 'e',\n",
       " 'ediff1d',\n",
       " 'einsum',\n",
       " 'einsum_path',\n",
       " 'emath',\n",
       " 'empty',\n",
       " 'empty_like',\n",
       " 'equal',\n",
       " 'errstate',\n",
       " 'euler_gamma',\n",
       " 'exp',\n",
       " 'exp2',\n",
       " 'expand_dims',\n",
       " 'expm1',\n",
       " 'extract',\n",
       " 'eye',\n",
       " 'fabs',\n",
       " 'fastCopyAndTranspose',\n",
       " 'fft',\n",
       " 'fft_msg',\n",
       " 'fill_diagonal',\n",
       " 'find_common_type',\n",
       " 'finfo',\n",
       " 'fix',\n",
       " 'flatiter',\n",
       " 'flatnonzero',\n",
       " 'flexible',\n",
       " 'flip',\n",
       " 'fliplr',\n",
       " 'flipud',\n",
       " 'float128',\n",
       " 'float16',\n",
       " 'float32',\n",
       " 'float64',\n",
       " 'float_',\n",
       " 'float_power',\n",
       " 'floating',\n",
       " 'floor',\n",
       " 'floor_divide',\n",
       " 'fmax',\n",
       " 'fmin',\n",
       " 'fmod',\n",
       " 'format_float_positional',\n",
       " 'format_float_scientific',\n",
       " 'format_parser',\n",
       " 'frexp',\n",
       " 'frombuffer',\n",
       " 'fromfile',\n",
       " 'fromfunction',\n",
       " 'fromiter',\n",
       " 'frompyfunc',\n",
       " 'fromregex',\n",
       " 'fromstring',\n",
       " 'full',\n",
       " 'full_like',\n",
       " 'fv',\n",
       " 'gcd',\n",
       " 'generic',\n",
       " 'genfromtxt',\n",
       " 'geomspace',\n",
       " 'get_array_wrap',\n",
       " 'get_include',\n",
       " 'get_printoptions',\n",
       " 'getbufsize',\n",
       " 'geterr',\n",
       " 'geterrcall',\n",
       " 'geterrobj',\n",
       " 'gradient',\n",
       " 'greater',\n",
       " 'greater_equal',\n",
       " 'half',\n",
       " 'hamming',\n",
       " 'hanning',\n",
       " 'heaviside',\n",
       " 'histogram',\n",
       " 'histogram2d',\n",
       " 'histogram_bin_edges',\n",
       " 'histogramdd',\n",
       " 'hsplit',\n",
       " 'hstack',\n",
       " 'hypot',\n",
       " 'i0',\n",
       " 'identity',\n",
       " 'ifft',\n",
       " 'iinfo',\n",
       " 'imag',\n",
       " 'in1d',\n",
       " 'index_exp',\n",
       " 'indices',\n",
       " 'inexact',\n",
       " 'inf',\n",
       " 'info',\n",
       " 'infty',\n",
       " 'inner',\n",
       " 'insert',\n",
       " 'int0',\n",
       " 'int16',\n",
       " 'int32',\n",
       " 'int64',\n",
       " 'int8',\n",
       " 'int_',\n",
       " 'intc',\n",
       " 'integer',\n",
       " 'interp',\n",
       " 'intersect1d',\n",
       " 'intp',\n",
       " 'invert',\n",
       " 'ipmt',\n",
       " 'irr',\n",
       " 'is_busday',\n",
       " 'isclose',\n",
       " 'iscomplex',\n",
       " 'iscomplexobj',\n",
       " 'isfinite',\n",
       " 'isfortran',\n",
       " 'isin',\n",
       " 'isinf',\n",
       " 'isnan',\n",
       " 'isnat',\n",
       " 'isneginf',\n",
       " 'isposinf',\n",
       " 'isreal',\n",
       " 'isrealobj',\n",
       " 'isscalar',\n",
       " 'issctype',\n",
       " 'issubclass_',\n",
       " 'issubdtype',\n",
       " 'issubsctype',\n",
       " 'iterable',\n",
       " 'ix_',\n",
       " 'kaiser',\n",
       " 'kron',\n",
       " 'lcm',\n",
       " 'ldexp',\n",
       " 'left_shift',\n",
       " 'less',\n",
       " 'less_equal',\n",
       " 'lexsort',\n",
       " 'linspace',\n",
       " 'little_endian',\n",
       " 'load',\n",
       " 'loads',\n",
       " 'loadtxt',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log1p',\n",
       " 'log2',\n",
       " 'logaddexp',\n",
       " 'logaddexp2',\n",
       " 'logical_and',\n",
       " 'logical_not',\n",
       " 'logical_or',\n",
       " 'logical_xor',\n",
       " 'logn',\n",
       " 'logspace',\n",
       " 'longcomplex',\n",
       " 'longdouble',\n",
       " 'longfloat',\n",
       " 'longlong',\n",
       " 'lookfor',\n",
       " 'ma',\n",
       " 'mafromtxt',\n",
       " 'mask_indices',\n",
       " 'mat',\n",
       " 'math',\n",
       " 'matmul',\n",
       " 'matrix',\n",
       " 'maximum',\n",
       " 'maximum_sctype',\n",
       " 'may_share_memory',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'memmap',\n",
       " 'meshgrid',\n",
       " 'mgrid',\n",
       " 'min_scalar_type',\n",
       " 'minimum',\n",
       " 'mintypecode',\n",
       " 'mirr',\n",
       " 'mod',\n",
       " 'modf',\n",
       " 'moveaxis',\n",
       " 'msort',\n",
       " 'multiply',\n",
       " 'nan',\n",
       " 'nan_to_num',\n",
       " 'nanargmax',\n",
       " 'nanargmin',\n",
       " 'nancumprod',\n",
       " 'nancumsum',\n",
       " 'nanmax',\n",
       " 'nanmean',\n",
       " 'nanmedian',\n",
       " 'nanmin',\n",
       " 'nanpercentile',\n",
       " 'nanprod',\n",
       " 'nanquantile',\n",
       " 'nanstd',\n",
       " 'nansum',\n",
       " 'nanvar',\n",
       " 'nbytes',\n",
       " 'ndarray',\n",
       " 'ndenumerate',\n",
       " 'ndfromtxt',\n",
       " 'ndim',\n",
       " 'ndindex',\n",
       " 'nditer',\n",
       " 'negative',\n",
       " 'nested_iters',\n",
       " 'newaxis',\n",
       " 'nextafter',\n",
       " 'nonzero',\n",
       " 'not_equal',\n",
       " 'nper',\n",
       " 'npv',\n",
       " 'number',\n",
       " 'obj2sctype',\n",
       " 'object0',\n",
       " 'object_',\n",
       " 'ogrid',\n",
       " 'ones',\n",
       " 'ones_like',\n",
       " 'outer',\n",
       " 'packbits',\n",
       " 'pad',\n",
       " 'partition',\n",
       " 'percentile',\n",
       " 'pi',\n",
       " 'piecewise',\n",
       " 'place',\n",
       " 'pmt',\n",
       " 'poly',\n",
       " 'poly1d',\n",
       " 'polyadd',\n",
       " 'polyder',\n",
       " 'polydiv',\n",
       " 'polyfit',\n",
       " 'polyint',\n",
       " 'polymul',\n",
       " 'polysub',\n",
       " 'polyval',\n",
       " 'positive',\n",
       " 'power',\n",
       " 'ppmt',\n",
       " 'print_function',\n",
       " 'printoptions',\n",
       " 'prod',\n",
       " 'product',\n",
       " 'promote_types',\n",
       " 'ptp',\n",
       " 'put',\n",
       " 'put_along_axis',\n",
       " 'putmask',\n",
       " 'pv',\n",
       " 'quantile',\n",
       " 'r_',\n",
       " 'rad2deg',\n",
       " 'radians',\n",
       " 'rand',\n",
       " 'randn',\n",
       " 'random',\n",
       " 'rate',\n",
       " 'ravel',\n",
       " 'ravel_multi_index',\n",
       " 'real',\n",
       " 'real_if_close',\n",
       " 'rec',\n",
       " 'recarray',\n",
       " 'recfromcsv',\n",
       " 'recfromtxt',\n",
       " 'reciprocal',\n",
       " 'record',\n",
       " 'remainder',\n",
       " 'repeat',\n",
       " 'require',\n",
       " 'reshape',\n",
       " 'resize',\n",
       " 'result_type',\n",
       " 'right_shift',\n",
       " 'rint',\n",
       " 'roll',\n",
       " 'rollaxis',\n",
       " 'roots',\n",
       " 'rot90',\n",
       " 'round_',\n",
       " 'row_stack',\n",
       " 's_',\n",
       " 'safe_eval',\n",
       " 'save',\n",
       " 'savetxt',\n",
       " 'savez',\n",
       " 'savez_compressed',\n",
       " 'sctype2char',\n",
       " 'sctypeDict',\n",
       " 'sctypeNA',\n",
       " 'sctypes',\n",
       " 'searchsorted',\n",
       " 'select',\n",
       " 'set_numeric_ops',\n",
       " 'set_printoptions',\n",
       " 'set_string_function',\n",
       " 'setbufsize',\n",
       " 'setdiff1d',\n",
       " 'seterr',\n",
       " 'seterrcall',\n",
       " 'seterrobj',\n",
       " 'setxor1d',\n",
       " 'shape',\n",
       " 'shares_memory',\n",
       " 'short',\n",
       " 'show_config',\n",
       " 'show_numpy_config',\n",
       " 'sign',\n",
       " 'signbit',\n",
       " 'signedinteger',\n",
       " 'sin',\n",
       " 'sinc',\n",
       " 'single',\n",
       " 'singlecomplex',\n",
       " 'sinh',\n",
       " 'size',\n",
       " 'sometrue',\n",
       " 'sort',\n",
       " 'sort_complex',\n",
       " 'source',\n",
       " 'spacing',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'squeeze',\n",
       " 'stack',\n",
       " 'std',\n",
       " 'str0',\n",
       " 'str_',\n",
       " 'string_',\n",
       " 'subtract',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'take_along_axis',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tensordot',\n",
       " 'test',\n",
       " 'tile',\n",
       " 'timedelta64',\n",
       " 'trace',\n",
       " 'tracemalloc_domain',\n",
       " 'transpose',\n",
       " 'trapz',\n",
       " 'tri',\n",
       " 'tril',\n",
       " 'tril_indices',\n",
       " 'tril_indices_from',\n",
       " 'trim_zeros',\n",
       " 'triu',\n",
       " 'triu_indices',\n",
       " 'triu_indices_from',\n",
       " 'true_divide',\n",
       " 'trunc',\n",
       " 'typeDict',\n",
       " 'typeNA',\n",
       " 'typecodes',\n",
       " 'typename',\n",
       " 'ubyte',\n",
       " 'ufunc',\n",
       " 'uint',\n",
       " 'uint0',\n",
       " 'uint16',\n",
       " 'uint32',\n",
       " 'uint64',\n",
       " 'uint8',\n",
       " 'uintc',\n",
       " 'uintp',\n",
       " 'ulonglong',\n",
       " 'unicode_',\n",
       " 'union1d',\n",
       " 'unique',\n",
       " 'unpackbits',\n",
       " 'unravel_index',\n",
       " 'unsignedinteger',\n",
       " 'unwrap',\n",
       " 'ushort',\n",
       " 'vander',\n",
       " 'var',\n",
       " 'vdot',\n",
       " 'vectorize',\n",
       " 'version',\n",
       " 'void',\n",
       " 'void0',\n",
       " 'vsplit',\n",
       " 'vstack',\n",
       " 'where',\n",
       " 'who',\n",
       " 'zeros',\n",
       " 'zeros_like']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.2617429 , 6.04950289])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].randomize()\n",
    "net([3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-1.41364637,  1.16071821],\n",
       "        [ 0.66063039,  0.42396354]]),\n",
       " array([ 0.06821949, -1.07695745]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].M, net.layers[0].b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the affine layer the identity transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].M = np.array([[1,0],[0,1]])\n",
    "net.layers[0].b = np.array([0,0])\n",
    "net([3,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.508647928518727"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.learning_potential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf934a4b7e0f4daca45486a9e98af769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 22])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net([7,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [0, 1]]),\n",
       " array([0, 0]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].M, net.layers[0].b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is learning doing to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.092601131822876e-32,\n",
       " 3.947771200004956e-30,\n",
       " 4.125582682120508e-31,\n",
       " 3.777904178910002e-30,\n",
       " 1.5037661005775538e-30,\n",
       " 1.633188592840376e-30,\n",
       " 1.3620176566706532e-30,\n",
       " 5.516826325697237e-31,\n",
       " 7.703719777548943e-33,\n",
       " 7.888609052210118e-31]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.learn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 22])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net([7,11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0],\n",
       "        [0, 1]]),\n",
       " array([0, 0]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layers[0].M, net.layers[0].b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take the map layer off again, how does it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench.rollback_net()\n",
    "bench.net.layers = bench.net.layers[:1]\n",
    "bench.checkpoint_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.53014188241033"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.ideal = lambda v: v\n",
    "bench.learning_potential()\n",
    "#bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It learns just fine, as expected. So we definitely have a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add a RELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.AffinityLayer at 0x7f0d293189d0>,\n",
       " <__main__.MapLayer at 0x7f0d292a86d0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench.net.layers = bench.net.layers[:1]\n",
    "leak = 0\n",
    "bench.net.extend(MapLayer(lambda x: (x*(1+leak/2)+abs(x)*(1-leak/2))/2, lambda d: [leak,1][1 if d>0 else 0]))\n",
    "bench.net.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6587b6ead0ee4a0c9d6c0c76467f1d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bench.net.layers[0].randomize()\n",
    "bench.checkpoint_net()\n",
    "bench.ideal = lambda v: np.array([1,1])\n",
    "bench.knobs_plot_learning(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffinityLayer(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.18691118,  0.10949354],\n",
       "        [ 1.40113726, -0.73322905]]),\n",
       " array([-0.96443749, -0.11239461]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = net.layers[0]\n",
    "t.M, t.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
