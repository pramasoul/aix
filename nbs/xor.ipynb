{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we make `xor` with a net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xor(x,y)` is x != y, viz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "True ^ True, False ^ False, True ^ False, False ^ True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adopt \"CMOS logic levels\", where less than 1/2 is False, greater is True. Then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flexor(a:float, b:float) -> float:\n",
    "    return 1.0 if (a < 0.5) ^ (b < 0.5) else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flexor(0, 0), flexor(0,1), flexor(1,0), flexor(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions\n",
    "We need some functions implementing nonlinear operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    #return (lambda v: max(0,v))(x)\n",
    "    return np.vectorize(lambda v: max(0.0,v))(x)\n",
    "\n",
    "[(v, relu(v)) for v in np.arange(-2, 2, 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive(x):\n",
    "    return np.vectorize(lambda v: max(0, np.sign(v)))(x)\n",
    "\n",
    "[(v, positive(v)) for v in np.arange(-2, 2, 0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tanh_gradient(x):\n",
    "    return 1-np.tanh(x)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frombits(v) -> int:\n",
    "    p = 1\n",
    "    s = 0\n",
    "    for bit in v:\n",
    "        s += p * bit\n",
    "        p <<= 1\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frombits([1,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exactor:\n",
    "    \"\"\"Calculate exclusive-or using a network\"\"\"\n",
    "    def __init__(self):\n",
    "        self.m0 = np.array([-0.5, -0.5])\n",
    "        self.randomize()\n",
    "        \n",
    "    def randomize(self):\n",
    "        \"Randomize the matricies\"\n",
    "        self.m1 = np.random.randn(2,2)\n",
    "        self.m2 = np.random.randn(2)\n",
    "    \n",
    "    def make_perfect(self):\n",
    "        \"Set the matricies to a handmade value that gives perfect behavior\"\n",
    "        self.m0 = np.array([-0.5, -0.5])\n",
    "        self.m1 = np.array([[ 1.0, -1.0],\n",
    "                            [-1.0,  1.0]])\n",
    "        self.m2 = np.array([1.0, 1.0])\n",
    "    \n",
    "    def ideal(self, a:float, b:float) -> bool:\n",
    "        \"Calculates the ideal return value directly, to provide a reference\"\n",
    "        return 1 if (a > 0.5) ^ (b > 0.5) else 0\n",
    "        #return np.sign(-a*b)\n",
    "    \n",
    "    def netwise(self, a:float, b:float):\n",
    "        \"Calculate a single result using network primitives\"\n",
    "        v = self.net_lin(a, b)\n",
    "        v = self.p5 = 0 if v < 0.5 else 1\n",
    "        return v\n",
    "\n",
    "    def net_ana(self, a:float, b:float):\n",
    "        \"Calculate a single analog result using network primitives\"\n",
    "        v = self.p4 = np.tanh(self.net_lin(a, b))\n",
    "        return v\n",
    "\n",
    "    def net_lin(self, a:float, b:float):\n",
    "        \"The network output up to the last linear stage\"\n",
    "        input = np.array([a, b])\n",
    "        v = self.p0 = self.m0 + input\n",
    "        v = self.p1 = self.m1 @ input\n",
    "        v = self.p2 = relu(v)\n",
    "        v = self.p3 = np.dot(self.m2, v)\n",
    "        return v\n",
    "\n",
    "    def __call__(self, a, b):\n",
    "        \"Vectorized calculation of result using network\"\n",
    "        return np.vectorize(self.netwise)(a, b)\n",
    "\n",
    "    def loss(self):\n",
    "        \"L2 loss function of the network implementation\"\n",
    "        return sum((self.__call__(x,y) - self.ideal(x,y))**2 for x in (-1, 1) for y in (-1, 1))\n",
    "    \n",
    "    def aloss(self):\n",
    "        \"L2 loss function of the network analog implementation\"\n",
    "        return sum((self.net_ana(x,y) - self.ideal(x,y))**2 for x in (-1, 1) for y in (-1, 1))\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return F\"Exactor m0={self.m0}, m1={self.m1}, m2={self.m2})\"\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try out the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor = Exactor()\n",
    "exor\n",
    "exor.net_lin(1.0,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.net_ana(1.0,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.netwise(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (0, 1):\n",
    "    for y in (0, 1):\n",
    "        print(exor.ideal(x, y), exor(x,y), exor.net_ana(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.loss(), exor.aloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.make_perfect()\n",
    "print(exor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (0, 1):\n",
    "    for y in (0, 1):\n",
    "        print(exor.ideal(x, y), exor(x,y), exor.p0, exor.p1, exor.p2, exor.p3, exor.p5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.loss(), exor.aloss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exor.randomize()\n",
    "exor.loss(), exor.aloss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we find working matricies by trying random matricies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = 1e300\n",
    "best_aloss = 1e300\n",
    "best_repr = \"\"\n",
    "for n in range(10000):\n",
    "    exor.randomize()\n",
    "    #if n == 6789:\n",
    "    #    exor.make_perfect()\n",
    "    loss = exor.loss()\n",
    "    if best_loss > loss:\n",
    "        best_loss = loss\n",
    "        best_repr = repr(exor)\n",
    "    aloss = exor.aloss()\n",
    "    if best_aloss > aloss:\n",
    "        best_aloss = aloss\n",
    "        best_arepr = repr(exor)\n",
    "    if loss == 0:\n",
    "        print(F\"Success after {n+1} tries: {exor}\")\n",
    "        break\n",
    "if exor.loss() > 0:\n",
    "    print(F\"Failure, none of {n+1} random tries worked\")\n",
    "print(f\"best net loss:{best_loss}, Best net:{best_repr}\")\n",
    "print(f\"best net aloss:{best_aloss}, Best anet:{best_arepr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A less delicate network implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FIXME: update to [0,1] logic and analog and so forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flexor:\n",
    "    \"\"\"A more robust XOR\n",
    "    Returns the sign of (|x-y| - |x+y|) where x, y are inputs\"\"\"\n",
    "    def __init__(self):\n",
    "        self.randomize()\n",
    "        \n",
    "    def randomize(self):\n",
    "        \"Randomize the matricies\"\n",
    "        self.m1 = np.random.randn(4,2)\n",
    "        self.m2 = np.random.randn(4)\n",
    "    \n",
    "    def make_perfect(self):\n",
    "        \"Set the matricies to a handmade value that gives perfect behavior\"\n",
    "        self.m1 = np.array([[ 1.0, -1.0],\n",
    "                            [-1.0,  1.0],\n",
    "                            [ 1.0,  1.0],\n",
    "                            [-1.0, -1.0]])\n",
    "        self.m2 = np.array([1.0, 1.0, -1.0, -1.0])\n",
    "    \n",
    "    def ideal(self, a:float, b:float) -> bool:\n",
    "        \"Calculates the ideal return value directly, to provide a reference\"\n",
    "        return np.sign(-a*b)\n",
    "    \n",
    "    def netwise(self, a:float, b:float) -> bool:\n",
    "        \"Calculate a single result using network primitives\"\n",
    "        input = np.array([[a],\n",
    "                          [b]])\n",
    "        v = self.p1 = self.m1 @ input\n",
    "        v = self.p2 = relu(v)\n",
    "        v = self.p3 = np.dot(self.m2, v)\n",
    "        v = self.p4 = relu(v)\n",
    "        v = self.p5 = (-1,1)[int(np.sign(v)[0])]\n",
    "        return v\n",
    "\n",
    "    def __call__(self, a, b):\n",
    "        \"Vectorized calculation of result using network\"\n",
    "        return np.vectorize(self.netwise)(a, b)\n",
    "\n",
    "    def loss(self):\n",
    "        \"L2 loss function of the network implementation\"\n",
    "        return sum((self.__call__(x,y) - self.ideal(x,y))**2 for x in (-1, 1) for y in (-1, 1))\n",
    "    \n",
    "    def goodness(self):\n",
    "        \"analog goodness function\"\n",
    "        rv = 0.0\n",
    "        for x in (-1, 1):\n",
    "            for y in (-1, 1):\n",
    "                _ = self.netwise(x, y)\n",
    "                rv += self.p4 * self.ideal(x,y)\n",
    "        return rv[0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return F\"Flexor(m1={self.m1}, m2={self.m2})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor = Flexor()\n",
    "flor.m1, flor.m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (-1, 1):\n",
    "    for y in (-1, 1):\n",
    "        print(flor.ideal(x, y), '\\tres:', flor(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.loss(), flor.goodness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.make_perfect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in (-1, 1):\n",
    "    for y in (-1, 1):\n",
    "        print(flor.ideal(x, y), flor(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.loss(), flor.goodness()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.randomize()\n",
    "flor.loss(), flor.goodness()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we find working matricies by trying random matricies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(10000):\n",
    "    flor.randomize()\n",
    "    if flor.loss() == 0:\n",
    "        print(F\"Success after {n+1} tries:\\n{flor}\")\n",
    "        break\n",
    "if flor.loss() > 0:\n",
    "    print(F\"Failure, none of {n+1} random tries worked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flor.loss(), flor.goodness()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
