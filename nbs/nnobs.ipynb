{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "empirical-auditor",
   "metadata": {},
   "source": [
    "# Neural Net observatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.max_open_warning'] = 0\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-assessment",
   "metadata": {},
   "source": [
    "Fetch our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer\n",
    "from nnbench import NNBench\n",
    "from nnvis import NNVis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-asthma",
   "metadata": {},
   "source": [
    "Use [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-blink",
   "metadata": {},
   "source": [
    "# Multiprocessing\n",
    "We run the net training in a child process, so that it can proceed while we observe and analyze partial results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-preparation",
   "metadata": {},
   "source": [
    "## Tooling\n",
    " * `JSONConn` over the Process Pipe\n",
    " -- Not seeing the exception on `recv()` of a closed connection, so we accomplish a close by a non-JSON message of four bytes of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sought-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from multiprocessing import Process, Pipe\n",
    "import multiprocessing as mp\n",
    "import json\n",
    "from time import sleep\n",
    "\n",
    "class JSONConn():\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "        \n",
    "    def send(self, v):\n",
    "        self.conn.send_bytes(json.dumps(v).encode('utf8'))\n",
    "        \n",
    "    def poll(self):\n",
    "        return self.conn.poll()\n",
    "    \n",
    "    def recv(self):\n",
    "        r = self.conn.recv_bytes()\n",
    "        if r == bytes(4):\n",
    "            self.close()\n",
    "            raise EOFError\n",
    "        return json.loads(r)\n",
    "        \n",
    "    def close(self):\n",
    "        self.conn.send_bytes(bytes(4))\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-chorus",
   "metadata": {},
   "source": [
    "## The child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expanded-pixel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(conn):\n",
    "    jc = JSONConn(conn)\n",
    " \n",
    "    net = Network()\n",
    "    net.extend(AffineLayer(2,2))\n",
    "    net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "    net.extend(AffineLayer(2,1))\n",
    "    net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "\n",
    "    training_batch = (np.array([[-0.5, -0.5],\n",
    "                                [-0.5,  0.5],\n",
    "                                [ 0.5,  0.5],\n",
    "                                [ 0.5, -0.5]]),\n",
    "                      np.array([[-0.5],\n",
    "                                [ 0.5],\n",
    "                                [-0.5],\n",
    "                                [ 0.5]]))\n",
    "\n",
    "    batch_ctr = 0\n",
    "    batch_to = 0\n",
    "    report_state = True\n",
    "    done = False\n",
    "\n",
    "    for i in range(100):\n",
    "        if done:\n",
    "            break\n",
    "    #while not done:\n",
    "        txm = dict()\n",
    "        \n",
    "        # Check for new instructions\n",
    "        while jc.poll():\n",
    "            rxm = jc.recv()\n",
    "            print(rxm)\n",
    "            for k,v in rxm.items():\n",
    "                if k == 'eta':\n",
    "                    net.eta = v\n",
    "                elif k == 'batch to':\n",
    "                    batch_to = v\n",
    "                elif k == 'tell state':\n",
    "                    report_state = True\n",
    "                elif k == 'shutdown':\n",
    "                    print(f\"got shutdown at batch {batch_ctr}\")\n",
    "                    done = True\n",
    "        \n",
    "        # Report states if it's the right batch phase, or if asked to\n",
    "        report_state = report_state or batch_ctr % 10 == 0 and last_state_report_at_batch < batch_ctr\n",
    "\n",
    "        if report_state:\n",
    "            txm['eta'] = [batch_ctr, net.eta]\n",
    "            txm['sv'] = [batch_ctr, list(float(v) for v in net.state_vector())]\n",
    "            last_state_report_at_batch = batch_ctr\n",
    "            report_state = False\n",
    "            \n",
    "        # Run a learning step if we aren't at the target number of steps\n",
    "        if batch_to > batch_ctr:\n",
    "            loss = net.learn([training_batch])\n",
    "            batch_ctr += 1\n",
    "            txm['loss'] = [batch_ctr, loss]\n",
    "            time.sleep(0.1) # Pretend this is a time-consuming calculation\n",
    "        else:\n",
    "            time.sleep(0.05)\n",
    "            \n",
    "        jc.send(txm)\n",
    "\n",
    "    jc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-digit",
   "metadata": {},
   "source": [
    "## The parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-hampshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import rx\n",
    "from rx import Observable\n",
    "from rx.subject import Subject\n",
    "from rx import operators as op\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-correction",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    def chew(time_limit):\n",
    "        print('.', end='')\n",
    "        time.sleep(time_limit)\n",
    "\n",
    "    # Fork the worker process\n",
    "    ipc_pipe = mp.Pipe()\n",
    "    parent_conn, child_conn = ipc_pipe\n",
    "    jc = JSONConn(parent_conn)\n",
    "    p = mp.Process(target=f, args=(child_conn,))\n",
    "    \n",
    "    \n",
    "    # Set up some visibility widgets\n",
    "    batch_w = widgets.FloatText(value=-1.0, description='Batch:', max_width=6, disabled=False)\n",
    "    loss_w = widgets.FloatText(value=-1.0, description='Loss:', max_width=6, disabled=False)\n",
    "    display(batch_w, loss_w)\n",
    "    \n",
    "    shut_down_child = False\n",
    "    def shutdown_child(w):\n",
    "        print('sending shutdown from shutdown_child')\n",
    "        jc.send({'shutdown': 'now'})\n",
    "        shut_down_child = True\n",
    "    \n",
    "    # Set up a button to stop the worker\n",
    "    shutdown_b_w = widgets.Button(description=\"Shutdown worker\")\n",
    "    #shutdown_b_w.on_click(lambda w: jc.send({'shutdown': 'now'}))\n",
    "    shutdown_b_w.on_click(shutdown_child)\n",
    "    display(shutdown_b_w)\n",
    "    \n",
    "    def set_w_value(w, val):\n",
    "        ov = w.value\n",
    "        w.value = val\n",
    "        return ov\n",
    "\n",
    "    # Process worker messages into topic observables\n",
    "    worker_messages_s = rx.subject.Subject()\n",
    "    burst_messages_s = worker_messages_s.pipe(\n",
    "        op.flat_map(lambda m: m.items()))\n",
    "    loss_s = burst_messages_s.pipe(\n",
    "        op.filter(lambda t: t[0] == 'loss'),\n",
    "        op.map(lambda t: t[1]))\n",
    "    sv_s = burst_messages_s.pipe(\n",
    "        op.filter(lambda t: t[0] == 'sv'),\n",
    "        op.map(lambda t: t[1]))\n",
    "    eta_s = burst_messages_s.pipe(\n",
    "        op.filter(lambda t: t[0] == 'eta'),\n",
    "        op.map(lambda t: t[1]))\n",
    "\n",
    "    loss_s.subscribe(lambda t: set_w_value(batch_w, t[0]) + set_w_value(loss_w, t[1]))\n",
    "    loss_s.pipe(op.take_last(1)).subscribe(print) # show the last loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advanced-franklin",
   "metadata": {},
   "source": [
    "### mainloop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-passage",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    p.start()\n",
    "    jc.send({'batch to': 50})\n",
    "    \n",
    "    #for i in range(110):\n",
    "    done = False\n",
    "    while not done:\n",
    "        if jc.poll():\n",
    "            try:\n",
    "                m = jc.recv()\n",
    "                worker_messages_s.on_next(m)\n",
    "            except EOFError:\n",
    "                worker_messages_s.on_completed()\n",
    "                print(\"sender closed\")\n",
    "                done = True\n",
    "        else:\n",
    "            if shut_down_child:\n",
    "                print('sending shutdown')\n",
    "                jc.send({'shutdown': 'now'})\n",
    "            chew(0.1)\n",
    "\n",
    "    p.join()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-defense",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"stop here if entering from above\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-reduction",
   "metadata": {},
   "source": [
    "## UI using `asyncio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "%gui asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-atlantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "def wait_for_change(widget, value):\n",
    "    future = asyncio.Future()\n",
    "    def getvalue(change):\n",
    "        # make the new value available\n",
    "        future.set_result(change.new)\n",
    "        widget.unobserve(getvalue, value)\n",
    "    widget.observe(getvalue, value)\n",
    "    return future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntSlider, Output\n",
    "slider = IntSlider()\n",
    "out = Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def f():\n",
    "    for i in range(10):\n",
    "        out.append_stdout('did work ' + str(i) + '\\n')\n",
    "        x = await wait_for_change(slider, 'value')\n",
    "        out.append_stdout('async function continued with value ' + str(x) + '\\n')\n",
    "\n",
    "async def g():\n",
    "    out.clear_output()\n",
    "\n",
    "asyncio.create_task(g())\n",
    "asyncio.create_task(f())\n",
    "\n",
    "slider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-agenda",
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpful-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quantitative-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "slider.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "progress = widgets.FloatProgress(value=0.0, min=0.0, max=1.0)\n",
    "\n",
    "def work(progress):\n",
    "    total = 100\n",
    "    for i in range(total):\n",
    "        time.sleep(0.2)\n",
    "        progress.value = float(i+1)/total\n",
    "\n",
    "thread = threading.Thread(target=work, args=(progress,))\n",
    "display(progress)\n",
    "thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-scale",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = widgets.Output(layout={'border': '1px solid black'})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-simulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with out:\n",
    "    print(\"yo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "descending-focus",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
