{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "scheduled-ground",
   "metadata": {},
   "source": [
    "# Neural Net observatory\n",
    "We run the net training in a child process, so that it can proceed while we observe and analyze partial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-perry",
   "metadata": {},
   "source": [
    "FIXME: clean up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.max_open_warning'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import trio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "french-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import rx\n",
    "from rx import Observable\n",
    "from rx.subject import Subject\n",
    "from rx import operators as op\n",
    "from sidecar import Sidecar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-senate",
   "metadata": {},
   "source": [
    "Fetch our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subsequent-coordinator",
   "metadata": {},
   "source": [
    "# A global (within the parent) state object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informative-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "g = Thing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-chile",
   "metadata": {},
   "source": [
    "# Tooling\n",
    " * `JSONConn` over the Process Pipe\n",
    " -- Not seeing the exception on `recv()` of a closed connection, so we accomplish a close by a non-JSON message of four bytes of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reflected-breakdown",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONConn():\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "        \n",
    "    def send(self, v):\n",
    "        self.conn.send_bytes(json.dumps(v).encode('utf8'))\n",
    "        \n",
    "    def poll(self):\n",
    "        return self.conn.poll()\n",
    "    \n",
    "    def recv(self):\n",
    "        r = self.conn.recv_bytes()\n",
    "        if r == bytes(4):\n",
    "            self.close()\n",
    "            raise EOFError\n",
    "        return json.loads(r)\n",
    "        \n",
    "    def close(self):\n",
    "        self.conn.send_bytes(bytes(4))\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileSystemConn():\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.outf = open(fname, 'wb')\n",
    "        \n",
    "    def send(self, v):\n",
    "        self.outf.write(json.dumps(v).encode('utf8'))\n",
    "        self.outf.write('\\n'.encode('utf8'))\n",
    "        \n",
    "    def poll(self):\n",
    "        raise UnimplementedError\n",
    "    \n",
    "    def recv(self):\n",
    "        raise UnimplementedError\n",
    "        \n",
    "    def close(self):\n",
    "        self.outf.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-container",
   "metadata": {},
   "source": [
    "# The Machine Learning compute process\n",
    "* Contain the ML model\n",
    "* Run in a separate O/S process for isolation\n",
    "* Communicate over `multiprocessing.Pipe` via messages each of which is a JSON-encoded dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-austin",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-armenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "net.extend(AffineLayer(2,2))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "net.extend(AffineLayer(2,1))\n",
    "net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thirty-remove",
   "metadata": {},
   "source": [
    "## The training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appropriate-miami",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch = (np.array([[-0.5, -0.5],\n",
    "                            [-0.5,  0.5],\n",
    "                            [ 0.5,  0.5],\n",
    "                            [ 0.5, -0.5]]),\n",
    "                  np.array([[-0.5],\n",
    "                            [ 0.5],\n",
    "                            [-0.5],\n",
    "                            [ 0.5]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peripheral-negative",
   "metadata": {},
   "source": [
    "## The training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNTrainProcess():\n",
    "    def __init__(self, net, training_batch):\n",
    "        self.net = net\n",
    "        self.training_batch = training_batch\n",
    "        \n",
    "    def __call__(self, conn, fname):\n",
    "        # FIXME: less self. noise\n",
    "        jc = JSONConn(conn)\n",
    "        fc = FileSystemConn(fname)\n",
    "        net = self.net\n",
    "        training_batch = self.training_batch\n",
    "        \n",
    "        # Initialize a lot of variables that control the state machine\n",
    "        batch_ctr = 0\n",
    "        batch_to = 0\n",
    "        report_state = True\n",
    "        report_state_interval = 0\n",
    "        last_state_report_was_at_batch = 0\n",
    "        loss = None\n",
    "        last_reported_loss = None\n",
    "        last_loss_report_time = 0\n",
    "        loss_report_min_interval = 0.01\n",
    "        loss_report_max_interval = 0.1\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            txm = dict()\n",
    "\n",
    "            # Check for new instructions\n",
    "            while jc.poll():\n",
    "                rxm = jc.recv()\n",
    "                print(f\"compute process got {rxm}\")\n",
    "                for k,v in rxm.items():\n",
    "                    if k == 'eta':\n",
    "                        net.eta = v\n",
    "                    elif k == 'batch to':\n",
    "                        batch_to = v\n",
    "                    elif k == 'tell state':\n",
    "                        report_state = True\n",
    "                    elif k == 'randomize':\n",
    "                        np.random.seed = v\n",
    "                        for layer in net.layers:\n",
    "                            if hasattr(layer, 'randomize'):\n",
    "                                layer.randomize()\n",
    "                    elif k == 'report state every':\n",
    "                        report_state_interval = v\n",
    "                    elif k == 'shutdown':\n",
    "                        print(f\"compute process got shutdown at batch {batch_ctr}\")\n",
    "                        done = True\n",
    "\n",
    "            # Report states if it's the right batch phase, or if asked to\n",
    "            report_state = report_state or \\\n",
    "                            report_state_interval > 0 \\\n",
    "                            and batch_ctr % report_state_interval == 0 \\\n",
    "                            and last_state_report_was_at_batch < batch_ctr\n",
    "\n",
    "            if report_state:\n",
    "                txm['eta'] = [batch_ctr, net.eta]\n",
    "                txm['sv'] = [batch_ctr, list(float(v) for v in net.state_vector())]\n",
    "                last_state_report_was_at_batch = batch_ctr\n",
    "                report_state = False\n",
    "\n",
    "            # Run a learning step if we aren't at the target number of steps\n",
    "            if batch_to > batch_ctr:\n",
    "                loss = net.learn([training_batch])\n",
    "                batch_ctr += 1\n",
    "                # Report the loss when we reach the target number of batches\n",
    "                if batch_ctr == batch_to:\n",
    "                    txm['loss'] = [batch_ctr, loss]\n",
    "                #time.sleep(0.2) # Pretend this was a time-consuming calculation\n",
    "                #time.sleep(0.01) #DEBUG: rate limit\n",
    "\n",
    "            # Report the loss, with rate limiting, if it's changed since last report\n",
    "            if loss != last_reported_loss \\\n",
    "                    and time.time() - last_loss_report_time > loss_report_min_interval:\n",
    "                txm['loss'] = [batch_ctr, loss]\n",
    "                last_reported_loss = loss\n",
    "                last_loss_report_time = time.time()\n",
    "\n",
    "            # Report the loss, when it's been too long, and we're still working on it,\n",
    "            # even if the loss is unchanged, as a sort of heartbeat\n",
    "            if batch_to > batch_ctr \\\n",
    "                    and time.time() - last_loss_report_time > loss_report_max_interval:\n",
    "                txm['loss'] = [batch_ctr, loss]\n",
    "                last_reported_loss = loss\n",
    "                last_loss_report_time = time.time()\n",
    "\n",
    "            if txm:\n",
    "                jc.send(txm)\n",
    "                fc.send(txm)\n",
    "            elif batch_ctr >= batch_to:\n",
    "                time.sleep(0.1)\n",
    "\n",
    "        jc.close()\n",
    "        fc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-elimination",
   "metadata": {},
   "source": [
    "# The parent\n",
    "* Do work in a background thread, as coroutines in `trio`\n",
    "    * Burst and route received messages from ML compute process using ReactiveX\n",
    "    * Interact with the UI widgets\n",
    "* Leave the foreground free for the notebook and its widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-effort",
   "metadata": {},
   "source": [
    "## Set up the compute process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excellent-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below did not work with either of 'spawn' or 'forkserver'\n",
    "# It resulted in 'AttributeError: Can't get attribute 'f' on <module '__main__' (built-in)>'\n",
    "\"\"\"# Spawn the worker process (fork is risky)\n",
    "ctx = mp.get_context('forkserver') \n",
    "ipc_pipe = ctx.Pipe()\n",
    "parent_conn, child_conn = ipc_pipe\n",
    "jc = JSONConn(parent_conn)\n",
    "p = ctx.Process(target=f, args=(child_conn, 't1.jsons'))\n",
    "\"\"\"\n",
    "\n",
    "# Fork the compute process, but don't start it yet\n",
    "# Could be trouble for trio, viz. https://github.com/python-trio/trio/issues/1614\n",
    "# so we do this first, outside of any `trio.run`\n",
    "ipc_pipe = mp.Pipe()\n",
    "parent_conn, child_conn = ipc_pipe\n",
    "jc = JSONConn(parent_conn)\n",
    "train_process_obj = NNTrainProcess(net=net, training_batch=training_batch)\n",
    "#p = mp.Process(target=f, args=(child_conn, 't1.jsons'))\n",
    "p = mp.Process(target=train_process_obj, args=(child_conn, 't2.jsons'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generic-apache",
   "metadata": {},
   "source": [
    "## Build UI widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-consultancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some visibility widgets\n",
    "batch_w = widgets.FloatText(value=-1.0, description='Batch:', max_width=6, disabled=True)\n",
    "loss_w = widgets.FloatText(value=-1.0, description='Loss:', max_width=6, disabled=True)\n",
    "\n",
    "# Set up control widgets\n",
    "# Button to stop the worker\n",
    "shutdown_b_w = widgets.Button(description=\"Shutdown worker\")\n",
    "\n",
    "# Input field to modify batch_to, and button to submit it\n",
    "batch_to_w = widgets.IntText(value=50, description='target batches:')\n",
    "batch_to_b_w = widgets.Button(description=\"submit target batches\")\n",
    "\n",
    "# Button to randomize the net\n",
    "randomize_b_w = widgets.Button(description=\"randomize net\")\n",
    "\n",
    "ui_widgets = (batch_w, loss_w, batch_to_w, batch_to_b_w, shutdown_b_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-grade",
   "metadata": {},
   "source": [
    "## ... and widget behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_w_value(w, val):\n",
    "    ov = w.value\n",
    "    w.value = val\n",
    "    return ov\n",
    "\n",
    "g.shut_down_child = False\n",
    "def shutdown_child(w):\n",
    "    #print('sending shutdown from shutdown_child')\n",
    "    jc.send({'shutdown': 'now'})\n",
    "    g.shut_down_child = True\n",
    "shutdown_b_w.on_click(shutdown_child)\n",
    "\n",
    "def submit_target_batches(w):\n",
    "    target_batches = batch_to_w.value\n",
    "    jc.send({'batch to': target_batches})\n",
    "batch_to_b_w.on_click(submit_target_batches)\n",
    "\n",
    "randomize_b_w.on_click(lambda w: jc.send({'randomize': np.random.rand()}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-alaska",
   "metadata": {},
   "source": [
    "## Build the ReactiveX pipelines\n",
    "These do basic parsing and routing of the response messages from the compute worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-learning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline to process worker messages into topic observables\n",
    "compute_worker_messages_s = rx.subject.Subject()\n",
    "burst_messages_s = compute_worker_messages_s.pipe(\n",
    "    op.flat_map(lambda m: m.items()))\n",
    "loss_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'loss'),\n",
    "    op.map(lambda t: t[1]))\n",
    "sv_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'sv'),\n",
    "    op.map(lambda t: t[1]))\n",
    "eta_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'eta'),\n",
    "    op.map(lambda t: t[1]))\n",
    "\n",
    "loss_s.subscribe(lambda t: set_w_value(batch_w, t[0]) + set_w_value(loss_w, t[1]))\n",
    "loss_s.subscribe(lambda t: loss_stripchart(t))\n",
    "#loss_s.subscribe(lambda t: print(t))\n",
    "loss_s.pipe(op.take_last(1)).subscribe(print) # show the last loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-coast",
   "metadata": {},
   "source": [
    "## Get a stripchart to display the losses\n",
    "We use a `Losschart`, which is specialized to displaying losses at irregular batch intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.stripchart import Losschart\n",
    "loss_stripchart = Losschart(10_000, height='250px', width='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-portal",
   "metadata": {},
   "source": [
    "# Background thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secure-fisher",
   "metadata": {},
   "source": [
    "## The background thread function is a `trio` task\n",
    "Its primary role is reading the messages from the forked compute process. Secondarily, it runs the `async` function `g.threadwork`, which returns a duration to sleep before calling it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_work(g, jc, s):\n",
    "\n",
    "    async def receive_from_compute_process(g, jc, s):\n",
    "        while not g.stop_requested:\n",
    "            try:\n",
    "                if jc.poll():\n",
    "                    try:\n",
    "                        m = jc.recv()\n",
    "                        s.on_next(m)\n",
    "                    except EOFError:\n",
    "                        s.on_completed()\n",
    "                        print(\"sender closed\")\n",
    "                        g.done = True\n",
    "                    except BrokenPipeError:\n",
    "                        s.on_completed()\n",
    "                        print(\"broken pipe\")\n",
    "                        g.done = True\n",
    "                else:\n",
    "                    await trio.sleep(0.01)\n",
    "            except OSError as e:\n",
    "                print(e)\n",
    "                g.done = True\n",
    "                break\n",
    "\n",
    "    async def worker(g):\n",
    "        while not g.stop_requested:\n",
    "            await trio.sleep(await g.threadwork())\n",
    "\n",
    "    \n",
    "    async def threadloop(g, jc, s):\n",
    "        async with trio.open_nursery() as nursery:\n",
    "            nursery.start_soon(receive_from_compute_process, g, jc, s)\n",
    "            nursery.start_soon(worker, g)\n",
    "        \n",
    "    trio.run(threadloop, g, jc, s)\n",
    "    g.done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-scottish",
   "metadata": {},
   "source": [
    "## Set up an idle job and the thread\n",
    "But don't start the thread just yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-conjunction",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def just_one():\n",
    "    g.work_ctr += 1\n",
    "    return 1\n",
    "\n",
    "g.work_ctr = 0\n",
    "g.threadwork = just_one\n",
    "g.stop_requested = False\n",
    "g.thread = threading.Thread(target=thread_work, args=(g, jc, compute_worker_messages_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-bacteria",
   "metadata": {},
   "source": [
    "## Build the UI panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Button, GridspecLayout, Layout\n",
    "\n",
    "grid = GridspecLayout(3, 2, height='700px',\n",
    "                      grid_gap='10px',\n",
    "                      justify_content='center',\n",
    "                      align_items='top')\n",
    "\n",
    "grid[0, 0] = loss_stripchart.fig\n",
    "grid[1,0] = widgets.VBox((loss_w,\n",
    "                           batch_w,\n",
    "                           batch_to_w,\n",
    "                           widgets.HBox((randomize_b_w, batch_to_b_w)),\n",
    "                           shutdown_b_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-kitchen",
   "metadata": {},
   "source": [
    "## Display the UI panel in a Sidecar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "temporal-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = Sidecar(title='NN Observatory')\n",
    "with dashboard:\n",
    "    display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-samuel",
   "metadata": {},
   "source": [
    "# Start background process, and `trio` thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.start()\n",
    "g.thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "horizontal-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"\"\"You can use the UI now. It's in the \"Sidecar\" at the right edge -->\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-personal",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.join()\n",
    "g.stop_requested = True\n",
    "dashboard.close()\n",
    "g.thread.is_alive() or g.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-credits",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-exchange",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "local-laugh",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"stop here if entering from above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latter-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoawait trio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
