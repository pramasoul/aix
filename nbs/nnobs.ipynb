{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "velvet-denmark",
   "metadata": {},
   "source": [
    "# Neural Net observatory\n",
    "We run the net training in a child process, so that it can proceed while we observe and analyze partial results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-reaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#%matplotlib inline\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complimentary-joshua",
   "metadata": {},
   "source": [
    "FIXME: clean up imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.max_open_warning'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-allocation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import json\n",
    "import multiprocessing as mp\n",
    "import threading\n",
    "import time\n",
    "import trio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-birmingham",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from collections import defaultdict\n",
    "import rx\n",
    "from rx import Observable\n",
    "from rx.subject import Subject\n",
    "from rx import operators as op"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-situation",
   "metadata": {},
   "source": [
    "Fetch our tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer\n",
    "#from nnbench import NNBench\n",
    "#from nnvis import NNVis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-hamilton",
   "metadata": {},
   "source": [
    "Use [`ipywidgets`](https://ipywidgets.readthedocs.io/en/latest/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-guitar",
   "metadata": {},
   "source": [
    "# A global (within the parent) state object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-extraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thing:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "g = Thing()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-death",
   "metadata": {},
   "source": [
    "# Tooling\n",
    " * `JSONConn` over the Process Pipe\n",
    " -- Not seeing the exception on `recv()` of a closed connection, so we accomplish a close by a non-JSON message of four bytes of zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONConn():\n",
    "    def __init__(self, conn):\n",
    "        self.conn = conn\n",
    "        \n",
    "    def send(self, v):\n",
    "        self.conn.send_bytes(json.dumps(v).encode('utf8'))\n",
    "        \n",
    "    def poll(self):\n",
    "        return self.conn.poll()\n",
    "    \n",
    "    def recv(self):\n",
    "        r = self.conn.recv_bytes()\n",
    "        if r == bytes(4):\n",
    "            self.close()\n",
    "            raise EOFError\n",
    "        return json.loads(r)\n",
    "        \n",
    "    def close(self):\n",
    "        self.conn.send_bytes(bytes(4))\n",
    "        self.conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FileSystemConn():\n",
    "    def __init__(self, fname):\n",
    "        self.fname = fname\n",
    "        self.outf = open(fname, 'wb')\n",
    "        \n",
    "    def send(self, v):\n",
    "        self.outf.write(json.dumps(v).encode('utf8'))\n",
    "        self.outf.write('\\n'.encode('utf8'))\n",
    "        \n",
    "    def poll(self):\n",
    "        raise UnimplementedError\n",
    "    \n",
    "    def recv(self):\n",
    "        raise UnimplementedError\n",
    "        \n",
    "    def close(self):\n",
    "        self.outf.close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-extension",
   "metadata": {},
   "source": [
    "# The Machine Learning compute process\n",
    "* Contain the ML model\n",
    "* Run in a separate O/S process for isolation\n",
    "* Communicate over `multiprocessing.Pipe` via messages each of which is a JSON-encoded dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(conn, fname):\n",
    "    jc = JSONConn(conn)\n",
    "    fc = FileSystemConn(fname)\n",
    " \n",
    "    net = Network()\n",
    "    net.extend(AffineLayer(2,2))\n",
    "    net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "    net.extend(AffineLayer(2,1))\n",
    "    net.extend(MapLayer(np.tanh, lambda d: 1.0 - np.tanh(d)**2))\n",
    "\n",
    "    training_batch = (np.array([[-0.5, -0.5],\n",
    "                                [-0.5,  0.5],\n",
    "                                [ 0.5,  0.5],\n",
    "                                [ 0.5, -0.5]]),\n",
    "                      np.array([[-0.5],\n",
    "                                [ 0.5],\n",
    "                                [-0.5],\n",
    "                                [ 0.5]]))\n",
    "\n",
    "    # Initialize a lot of variables that control the state machine\n",
    "    batch_ctr = 0\n",
    "    batch_to = 0\n",
    "    report_state = True\n",
    "    report_state_interval = 0\n",
    "    last_state_report_was_at_batch = 0\n",
    "    last_reported_loss = None\n",
    "    loss = None\n",
    "    last_loss_report_time = 0\n",
    "    loss_report_min_interval = 0.01\n",
    "    loss_report_max_interval = 0.1\n",
    "    done = False\n",
    "\n",
    "    #for i in range(100):\n",
    "    #    if done:\n",
    "    #        break\n",
    "    while not done:\n",
    "        txm = dict()\n",
    "        \n",
    "        # Check for new instructions\n",
    "        while jc.poll():\n",
    "            rxm = jc.recv()\n",
    "            print(f\"compute process got {rxm}\")\n",
    "            for k,v in rxm.items():\n",
    "                if k == 'eta':\n",
    "                    net.eta = v\n",
    "                elif k == 'batch to':\n",
    "                    batch_to = v\n",
    "                elif k == 'tell state':\n",
    "                    report_state = True\n",
    "                elif k == 'report state every':\n",
    "                    report_state_interval = v\n",
    "                elif k == 'shutdown':\n",
    "                    print(f\"compute process got shutdown at batch {batch_ctr}\")\n",
    "                    done = True\n",
    "        \n",
    "        # Report states if it's the right batch phase, or if asked to\n",
    "        report_state = report_state or \\\n",
    "                        report_state_interval > 0 \\\n",
    "                        and batch_ctr % report_state_interval == 0 \\\n",
    "                        and last_state_report_was_at_batch < batch_ctr\n",
    "\n",
    "        if report_state:\n",
    "            txm['eta'] = [batch_ctr, net.eta]\n",
    "            txm['sv'] = [batch_ctr, list(float(v) for v in net.state_vector())]\n",
    "            last_state_report_was_at_batch = batch_ctr\n",
    "            report_state = False\n",
    "            \n",
    "        # Run a learning step if we aren't at the target number of steps\n",
    "        if batch_to > batch_ctr:\n",
    "            loss = net.learn([training_batch])\n",
    "            batch_ctr += 1\n",
    "            # Report the loss when we reach the target number of batches\n",
    "            if batch_ctr == batch_to:\n",
    "                txm['loss'] = [batch_ctr, loss]\n",
    "            #time.sleep(0.2) # Pretend this was a time-consuming calculation\n",
    "            #time.sleep(0.01) #DEBUG: rate limit\n",
    "            \n",
    "        # Report the loss, with rate limiting, if it's changed since last report\n",
    "        if loss != last_reported_loss \\\n",
    "                and time.time() - last_loss_report_time > loss_report_min_interval:\n",
    "            txm['loss'] = [batch_ctr, loss]\n",
    "            last_reported_loss = loss\n",
    "            last_loss_report_time = time.time()\n",
    "            \n",
    "        # Report the loss, when it's been too long, and we're still working on it\n",
    "        # even if the loss is unchanged, as a sort of heartbeat\n",
    "        if batch_to > batch_ctr and time.time() - last_loss_report_time > loss_report_max_interval:\n",
    "            txm['loss'] = [batch_ctr, loss]\n",
    "            last_reported_loss = loss\n",
    "            last_loss_report_time = time.time()\n",
    "            \n",
    "        if txm:\n",
    "            jc.send(txm)\n",
    "            fc.send(txm)\n",
    "        elif batch_ctr >= batch_to:\n",
    "            time.sleep(0.1)\n",
    "\n",
    "    jc.close()\n",
    "    fc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-classroom",
   "metadata": {},
   "source": [
    "# The parent\n",
    "* Do work in a background thread, as coroutines in `trio`\n",
    "    * Burst and route received messages from ML compute process using ReactiveX\n",
    "    * Interact with the UI widgets\n",
    "* Leave the foreground free for the notebook and its widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "million-addiction",
   "metadata": {},
   "source": [
    "## Set up the compute process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below did not work with either of 'spawn' or 'forkserver'\n",
    "# It resulted in 'AttributeError: Can't get attribute 'f' on <module '__main__' (built-in)>'\n",
    "\"\"\"# Spawn the worker process (fork is risky)\n",
    "ctx = mp.get_context('forkserver') \n",
    "ipc_pipe = ctx.Pipe()\n",
    "parent_conn, child_conn = ipc_pipe\n",
    "jc = JSONConn(parent_conn)\n",
    "p = ctx.Process(target=f, args=(child_conn, 't1.jsons'))\n",
    "\"\"\"\n",
    "\n",
    "# Fork the compute process, but don't start it yet\n",
    "# Could be trouble for trio, viz. https://github.com/python-trio/trio/issues/1614\n",
    "# so we do this first, outside of any `trio.run`\n",
    "ipc_pipe = mp.Pipe()\n",
    "parent_conn, child_conn = ipc_pipe\n",
    "jc = JSONConn(parent_conn)\n",
    "p = mp.Process(target=f, args=(child_conn, 't1.jsons'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-documentary",
   "metadata": {},
   "source": [
    "## Build UI widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "returning-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up some visibility widgets\n",
    "batch_w = widgets.FloatText(value=-1.0, description='Batch:', max_width=6, disabled=True)\n",
    "loss_w = widgets.FloatText(value=-1.0, description='Loss:', max_width=6, disabled=True)\n",
    "\n",
    "# Set up control widgets\n",
    "# Button to stop the worker\n",
    "shutdown_b_w = widgets.Button(description=\"Shutdown worker\")\n",
    "\n",
    "# Input field to modify batch_to, and button to submit it\n",
    "batch_to_w = widgets.IntText(value=50, description='target batches:')\n",
    "batch_to_b_w = widgets.Button(description=\"submit target batches\")\n",
    "\n",
    "ui_widgets = (batch_w, loss_w, batch_to_w, batch_to_b_w, shutdown_b_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "horizontal-pilot",
   "metadata": {},
   "source": [
    "## ... and widget behaviors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_w_value(w, val):\n",
    "    ov = w.value\n",
    "    w.value = val\n",
    "    return ov\n",
    "\n",
    "g.shut_down_child = False\n",
    "def shutdown_child(w):\n",
    "    #print('sending shutdown from shutdown_child')\n",
    "    jc.send({'shutdown': 'now'})\n",
    "    g.shut_down_child = True\n",
    "shutdown_b_w.on_click(shutdown_child)\n",
    "\n",
    "def submit_target_batches(w):\n",
    "    target_batches = batch_to_w.value\n",
    "    jc.send({'batch to': target_batches})\n",
    "batch_to_b_w.on_click(submit_target_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-estonia",
   "metadata": {},
   "source": [
    "## Build the ReactiveX pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-keeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pipeline to process worker messages into topic observables\n",
    "compute_worker_messages_s = rx.subject.Subject()\n",
    "burst_messages_s = compute_worker_messages_s.pipe(\n",
    "    op.flat_map(lambda m: m.items()))\n",
    "loss_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'loss'),\n",
    "    op.map(lambda t: t[1]))\n",
    "sv_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'sv'),\n",
    "    op.map(lambda t: t[1]))\n",
    "eta_s = burst_messages_s.pipe(\n",
    "    op.filter(lambda t: t[0] == 'eta'),\n",
    "    op.map(lambda t: t[1]))\n",
    "\n",
    "loss_s.subscribe(lambda t: set_w_value(batch_w, t[0]) + set_w_value(loss_w, t[1]))\n",
    "loss_s.subscribe(lambda t: sc(t))\n",
    "#loss_s.subscribe(lambda t: print(t))\n",
    "loss_s.pipe(op.take_last(1)).subscribe(print) # show the last loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-projector",
   "metadata": {},
   "source": [
    "## Make the strip chart for losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.stripchart import Losschart\n",
    "sc = Losschart(100, height='250px', width='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-movie",
   "metadata": {},
   "source": [
    "# Background thread"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-marks",
   "metadata": {},
   "source": [
    "## The background thread function is a `trio` task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thread_work(g, jc, s):\n",
    "\n",
    "    async def receive_from_compute_process(g, jc, s):\n",
    "        while not g.stop_requested:\n",
    "            try:\n",
    "                if jc.poll():\n",
    "                    try:\n",
    "                        m = jc.recv()\n",
    "                        s.on_next(m)\n",
    "                    except EOFError:\n",
    "                        s.on_completed()\n",
    "                        print(\"sender closed\")\n",
    "                        g.done = True\n",
    "                    except BrokenPipeError:\n",
    "                        s.on_completed()\n",
    "                        print(\"broken pipe\")\n",
    "                        g.done = True\n",
    "                else:\n",
    "                    await trio.sleep(0.01)\n",
    "            except OSError as e:\n",
    "                print(e)\n",
    "                g.done = True\n",
    "                break\n",
    "\n",
    "    async def worker(g):\n",
    "        while not g.stop_requested:\n",
    "            await trio.sleep(await g.threadwork())\n",
    "\n",
    "    \n",
    "    async def threadloop(g, jc, s):\n",
    "        async with trio.open_nursery() as nursery:\n",
    "            nursery.start_soon(receive_from_compute_process, g, jc, s)\n",
    "            nursery.start_soon(worker, g)\n",
    "        \n",
    "    trio.run(threadloop, g, jc, s)\n",
    "    g.done = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-austria",
   "metadata": {},
   "source": [
    "## Set up an idle job and the thread\n",
    "But don't start the thread just yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def just_one():\n",
    "    g.work_ctr += 1\n",
    "    return 1\n",
    "\n",
    "g.work_ctr = 0\n",
    "g.threadwork = just_one\n",
    "g.stop_requested = False\n",
    "g.thread = threading.Thread(target=thread_work, args=(g, jc, compute_worker_messages_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layout\n",
    "from ipywidgets import Button, GridspecLayout, Layout\n",
    "\n",
    "def create_expanded_button(description, button_style):\n",
    "    return Button(description=description,\n",
    "                  button_style=button_style,\n",
    "                  layout=Layout(height='auto', width='auto'))\n",
    "\n",
    "grid = GridspecLayout(5, 5, height='680px',\n",
    "                      grid_gap='10px',\n",
    "                      justify_content='center',\n",
    "                      align_items='top')\n",
    "\n",
    "grid[:2, :2] = sc.fig\n",
    "grid[2,:2] = widgets.VBox((loss_w, batch_w, batch_to_w, widgets.HBox((shutdown_b_w, batch_to_b_w))))\n",
    "display(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-treatment",
   "metadata": {},
   "source": [
    "# Start backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-thriller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(*ui_widgets)\n",
    "p.start()\n",
    "g.thread.start()\n",
    "#jc.send({'batch to': 50})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"You can use the UI now\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.stop_requested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "p.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "g.thread.is_alive() or g.thread.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-problem",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-haven",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"stop here if entering from above\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-tactics",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoawait trio"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
