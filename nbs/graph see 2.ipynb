{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "governing-refund",
   "metadata": {},
   "source": [
    "# neo4j graph fun"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-cream",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imported-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import neo4j\n",
    "import tools.neotools as nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pursuant-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from hashlib import sha256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache as cache\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-dayton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from sidecar import Sidecar\n",
    "from nnvis import NetResponsePlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-consortium",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_utils_neo4j import NumpyStore\n",
    "from nnbench import Thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-intersection",
   "metadata": {},
   "source": [
    "## Connecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-workstation",
   "metadata": {},
   "source": [
    "Need to get the `gpu-jupyter` and the `neo4j` docker containers connected. If run bare, something like:\n",
    "\n",
    "    docker network connect gpu-jupyter_default gpu-jupyter \n",
    "    docker network connect gpu-jupyter_default neo4j\n",
    "    docker network inspect gpu-jupyter_default \n",
    "    \n",
    "Docker has better ways than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = neo4j.GraphDatabase.driver(\"neo4j://172.19.0.2:7687\", auth=(\"neo4j\", \"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-toolbox",
   "metadata": {},
   "source": [
    "### Alive?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enclosed-rescue",
   "metadata": {},
   "source": [
    "# The Model\n",
    "    Investigation -> Experiment -> multiple ResultDAGs\n",
    "`ResultDAG` is\n",
    "\n",
    "    (netState, params)-[mutation]->(netState, params)-[mutation ...\n",
    "                     +-[mutation]->(netstate, params) ...\n",
    "etc. `mutation` can be a learning trajectory, or an edit.\n",
    "\n",
    "Perhaps `mutation` can be expressed in python.\n",
    "\n",
    "Generally the results of experiments are preferred to be reproducible, but they won't always be, when they import entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annual-flower",
   "metadata": {},
   "source": [
    "## Some neural nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import Network, Layer, IdentityLayer, AffineLayer, MapLayer\n",
    "from nnbench import NetMaker, NNMEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-diving",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm = NetMaker(NNMEG)\n",
    "xor_net = mnm('2x2tx1t')\n",
    "adc_net = mnm('1x8tx8tx3t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-marine",
   "metadata": {},
   "source": [
    "## ... and training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_training_batch = (np.array([[-0.5, -0.5],\n",
    "                            [-0.5,  0.5],\n",
    "                            [ 0.5,  0.5],\n",
    "                            [ 0.5, -0.5]]),\n",
    "                  np.array([[-0.5],\n",
    "                            [ 0.5],\n",
    "                            [-0.5],\n",
    "                            [ 0.5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adc(input):\n",
    "    m = max(0, min(7, int(8*input)))\n",
    "    return np.array([(m>>2)&1, (m>>1)&1, m&1]) * 2 - 1\n",
    "\n",
    "vadc = lambda v: np.array([adc(p) for p in v])\n",
    "#plot_ADC(vadc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "commercial-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0, 1, 1.0/(8*1)).reshape(-1,1) # 1 point in each output region\n",
    "adc_training_batch = (x, vadc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_run():\n",
    "    def get_sequence(tx, rv):\n",
    "        for record in tx.run(\"MATCH p=(head:net)-[:LEARNED*]->(tail:net) \"\n",
    "                             \"WHERE NOT ()-[:LEARNED]->(head) \"\n",
    "                             \"AND NOT (tail)-[:LEARNED]->() \"\n",
    "                             \"RETURN \"\n",
    "                             \"head, \"\n",
    "                             \"[x IN nodes(p) | x.ksv] as ksvs, \"\n",
    "                             \"[x IN nodes(p) | x.loss] as losses \"\n",
    "                            ):\n",
    "            rv.head = record['head']\n",
    "            rv.ksvs = record['ksvs']\n",
    "            rv.losses = record['losses']\n",
    "\n",
    "    rv = Thing\n",
    "    with driver.session() as session:\n",
    "        session.read_transaction(get_sequence, rv)\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_names_keys_from_experiment_and_procedure_names(ex_name, proc_name):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {name: $ex_name})\n",
    "-[:includes]->(proc:Procedure {name: $proc_name})\n",
    "-[:incorporates]->(par:Parameters)\n",
    "RETURN par.name as name, par.unikey as key\n",
    "\"\"\"\n",
    "    return [(r['name'], r['key']) for r in \n",
    "            nj.query_read_yield(driver, q, ex_name=ex_name, proc_name=proc_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-medicaid",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_names_keys_from_experiment_and_procedure_names('t2', 'Train ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-programmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_run(procedure_unikey):\n",
    "    q = \"\"\"\n",
    "MATCH (par:Parameters  {unikey: $key})-[:configures]->(head:net)\n",
    "MATCH p=(head)-[:LEARNED*]->(tail:net)\n",
    "WHERE NOT (tail)-[:LEARNED]->()\n",
    "RETURN \n",
    "    head.shorthand as shorthand,\n",
    "    [x IN nodes(p) | x.ksv] as ksvs,\n",
    "    [x IN nodes(p) | x.loss] as losses\n",
    "\"\"\"\n",
    "    r = nj.query_read_return_list(driver, q, key=procedure_unikey)\n",
    "    return dict(r[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_run('MSBTDgD7m87O3xMIV3FIXA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_from_experiment_and_procedure_names(ex_name, proc_name):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {name: $ex_name})\n",
    "-[:includes]->(proc:Procedure {name: $proc_name})\n",
    "-[:incorporates]->(par:Parameters)\n",
    "-[:configures]->(head:net)\n",
    "MATCH p=(head)-[:LEARNED*]->(tail:net)\n",
    "WHERE NOT (tail)-[:LEARNED]->()\n",
    "RETURN \n",
    "    par.name as name,\n",
    "    head.shorthand as shorthand,\n",
    "    [x IN nodes(p) | x.ksv] as ksvs,\n",
    "    [x IN nodes(p) | x.loss] as losses\n",
    "ORDER BY name\n",
    "\"\"\"\n",
    "    return [dict(r) for r in nj.query_read_yield(driver, q, ex_name=ex_name, proc_name=proc_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "nps = NumpyStore(driver)\n",
    "\n",
    "@cache\n",
    "def sv_from_ksv(ksv):\n",
    "    return nps[ksv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ix_or_default(seq, ix, default):\n",
    "    try:\n",
    "        return seq[ix]\n",
    "    except IndexError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loved-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_adcs_n(n):\n",
    "    for nrp, thing in zip(nrps, things):\n",
    "        nrp(sv_from_ksv(ix_or_default(thing.ksvs, n, thing.ksvs[-1])))\n",
    "    return [ix_or_default(thing.losses, n, 0) for thing in things]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "things = [Thing(**d) for d in data_from_experiment_and_procedure_names('t2', 'Train ADCs')]\n",
    "\n",
    "nets = [mnm(t.shorthand) for t in things]\n",
    "nrps = [NetResponsePlot(net, height='220px', margin=30, title=net.shorthand) for net in nets]\n",
    "\n",
    "frame_w = widgets.IntSlider(min=0,\n",
    "                            max=max(len(t.ksvs) for t in things)-1,\n",
    "                            step=1, value=0)\n",
    "\n",
    "# Skip the grid\n",
    "plots_box = widgets.Box(tuple(nrp.fig for nrp in nrps),\n",
    "                        layout=widgets.Layout(flex_flow='row wrap',\n",
    "                                             justify_content='space-around'))\n",
    "        \n",
    "with Sidecar(title='grid') as gside:\n",
    "    display(plots_box)\n",
    "    \n",
    "widgets.interact(show_adcs_n, n=frame_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-strap",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-contributor",
   "metadata": {},
   "source": [
    "# Scrapyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acknowledged-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"Scrapyard below\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-girlfriend",
   "metadata": {},
   "source": [
    "# Try Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(tx):\n",
    "    for record in tx.run(\"MATCH p=(head:net)-[:LEARNED*]->(tail:net)\"\n",
    "                         \"WHERE NOT ()-[:LEARNED]->(head)\"\n",
    "                         \"AND NOT (tail)-[:LEARNED]->()\"\n",
    "                         \"RETURN p, [x IN nodes(p) | x.ksv] as ksvs\"):\n",
    "        print(record['ksvs'])\n",
    "        p = record['p']\n",
    "        print(type(p))\n",
    "        print(record['ksvs'])\n",
    "        for r in p.relationships:\n",
    "            print(r.start_node['ksv'], r['ts'], r.end_node['ksv'])\n",
    "\n",
    "with driver.session() as session:\n",
    "    session.read_transaction(get_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(tx):\n",
    "    for record in tx.run(\"MATCH p=(head:net)-[:LEARNED*]->(tail:net) \"\n",
    "                         \"WHERE NOT ()-[:LEARNED]->(head) \"\n",
    "                         \"AND NOT (tail)-[:LEARNED]->() \"\n",
    "                         \"RETURN \"\n",
    "                         \"head, \"\n",
    "                         \"[x IN nodes(p) | x.ksv] as ksvs, \"\n",
    "                         \"[x IN nodes(p) | x.loss] as losses \"\n",
    "                        ):\n",
    "        head = record['head']\n",
    "        ksvs = record['ksvs']\n",
    "        losses = record['losses']\n",
    "        print(ksvs, losses)\n",
    "        print(head)\n",
    "        \n",
    "with driver.session() as session:\n",
    "    session.read_transaction(get_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conscious-badge",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = defaultdict(Thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-floor",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['a'].foo = 3\n",
    "d['b'].bar = lambda x: x*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-whole",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-seeker",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['b'].bar(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closing-translator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
