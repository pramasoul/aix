{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "guilty-niagara",
   "metadata": {},
   "source": [
    "# Graph Experiment 2: Experiment Preparation\n",
    "Set up experiments for the bots to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-brazil",
   "metadata": {},
   "source": [
    "## Capture code as strings\n",
    "We collect code from chosen cells as strings, and place them in nodes in the graph. The code is intended to be sufficient to reproduce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nnbench import NetMaker, NNMEG\n",
    "import secrets\n",
    "import time\n",
    "import tools.neotools as nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-basket",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2]) # Grab the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-enzyme",
   "metadata": {},
   "source": [
    "## Connecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intermediate-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = neo4j.GraphDatabase.driver(\"neo4j://neo4j:7687\", auth=(\"neo4j\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-county",
   "metadata": {},
   "source": [
    "# The graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "display(SVG('ml graphdb structure r2.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-andrews",
   "metadata": {},
   "source": [
    "# Prepare code for later `eval`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-defeat",
   "metadata": {},
   "source": [
    "## Create the net we will train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm = NetMaker(NNMEG)\n",
    "net = mnm('1x8tx8tx3tx3t')\n",
    "\n",
    "def adc(input):\n",
    "    m = max(0, min(7, int(8*input)))\n",
    "    return np.array([(m>>2)&1, (m>>1)&1, m&1]) * 2 - 1\n",
    "\n",
    "vadc = lambda v: np.array([adc(p) for p in v])\n",
    "\n",
    "x = np.arange(0, 1, 1.0/(8*8)).reshape(-1,1) # 8 points in each output region\n",
    "training_batch = (x, vadc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blocked-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-commitment",
   "metadata": {},
   "source": [
    "## First net node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_net_start_to_graph(driver, facts):\n",
    "    q = \"\"\"\n",
    "MATCH (par:Parameters {unikey: $parameters_unikey})\n",
    "CREATE (par)-[:configures]->(:net \n",
    "            {shorthand: $shorthand,\n",
    "                   ksv: $ksv,\n",
    "                  loss: $loss,\n",
    "                    ts: timestamp(),\n",
    "                  head: $head,\n",
    "    batches_from_start: 0})\n",
    "\"\"\"\n",
    "\n",
    "    nj.query_write(driver, q, **facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disciplinary-fossil",
   "metadata": {},
   "source": [
    "## Trained net nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_net_subsequent_to_graph(driver, facts):\n",
    "    q = \"\"\"\n",
    "MATCH (a:net {ksv: $prior_ksv})\n",
    "MERGE (a)-[:LEARNED\n",
    "         {batch_points: $batch_points,\n",
    "                  etas: $etas,\n",
    "    eta_change_batches: $eta_change_batches,\n",
    "  batches_this_segment: $batches_this_segment,\n",
    "                losses: $loss,\n",
    "            loss_steps: $loss_step,\n",
    "           traj_L2_sqs: $traj_L2_sq,\n",
    "   traj_cos_sq_signeds: $traj_cos_sq_signed,\n",
    "                    ts: timestamp()}]->\n",
    "(b:net\n",
    "          {shorthand: $shorthand,\n",
    "                 ksv: $ksv,\n",
    "                loss: $end_loss,\n",
    "                  ts: timestamp(),\n",
    "  batches_from_start: $batches_from_start})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medical-discussion",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-hobby",
   "metadata": {},
   "source": [
    "## Train, recording trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_an_increment(net, nps, properties):\n",
    "    loss = net.losses([training_batch])[0]\n",
    "    batch_ctr = 0\n",
    "    while loss > 1e-3:\n",
    "        batch_ctr_at_seg_start = batch_ctr\n",
    "        losses = []\n",
    "        etas = []\n",
    "        deltas = []\n",
    "        prior_loss = loss\n",
    "        while loss / prior_loss > 0.7071 and len(deltas) < 100:\n",
    "            if not etas or net.eta != etas[-1][1]:\n",
    "                etas.append([batch_ctr, net.eta])\n",
    "            loss = net.learn([training_batch])\n",
    "            if batch_ctr < 100 or batch_ctr % 100 == 0:\n",
    "                losses.append([batch_ctr, loss])\n",
    "                deltas.append([batch_ctr, net.deltas()])\n",
    "            batch_ctr += 1\n",
    "        #if losses[-1][0] < (batch_ctr-1):\n",
    "        #    losses.append([batch_ctr, loss])\n",
    "        if not deltas or deltas[-1][0] < (batch_ctr-1):\n",
    "            deltas.append((batch_ctr, net.deltas()))\n",
    "        properties = dict(zip(deltas[0][1]._fields, map(list, (zip(*(v[1] for v in deltas))))))\n",
    "        #properties = {}\n",
    "        properties['batch_points'] = [v[0] for v in deltas]\n",
    "        #properties['etas'] = etas\n",
    "        properties['etas'], properties['eta_change_batches'] = (list(v) for v in zip(*etas))\n",
    "        properties['batches_this_segment'] = batch_ctr - batch_ctr_at_seg_start\n",
    "        properties['ts'] = time.time()\n",
    "        properties['shorthand'] = net.shorthand\n",
    "        properties['ksv'] = nps.store(net.state_vector())\n",
    "        properties['end_loss'] = net.losses([training_batch])[0]\n",
    "        properties['experiment'] = 'ADC'\n",
    "        yield properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(net, nps):\n",
    "    loss = net.losses([training_batch])[0]\n",
    "    batch_ctr = 0\n",
    "    while loss > 1e-3:\n",
    "        batch_ctr_at_seg_start = batch_ctr\n",
    "        losses = []\n",
    "        etas = []\n",
    "        deltas = []\n",
    "        prior_loss = loss\n",
    "        while loss / prior_loss > 0.7071 and len(deltas) < 100:\n",
    "            if not etas or net.eta != etas[-1][1]:\n",
    "                etas.append([batch_ctr, net.eta])\n",
    "            loss = net.learn([training_batch])\n",
    "            if batch_ctr < 100 or batch_ctr % 100 == 0:\n",
    "                losses.append([batch_ctr, loss])\n",
    "                deltas.append([batch_ctr, net.deltas()])\n",
    "            batch_ctr += 1\n",
    "        #if losses[-1][0] < (batch_ctr-1):\n",
    "        #    losses.append([batch_ctr, loss])\n",
    "        if not deltas or deltas[-1][0] < (batch_ctr-1):\n",
    "            deltas.append((batch_ctr, net.deltas()))\n",
    "        properties = dict(zip(deltas[0][1]._fields, map(list, (zip(*(v[1] for v in deltas))))))\n",
    "        #properties = {}\n",
    "        properties['batch_points'] = [v[0] for v in deltas]\n",
    "        #properties['etas'] = etas\n",
    "        properties['etas'], properties['eta_change_batches'] = (list(v) for v in zip(*etas))\n",
    "        properties['batches_this_segment'] = batch_ctr - batch_ctr_at_seg_start\n",
    "        properties['ts'] = time.time()\n",
    "        properties['shorthand'] = net.shorthand\n",
    "        properties['ksv'] = nps.store(net.state_vector())\n",
    "        properties['end_loss'] = net.losses([training_batch])[0]\n",
    "        properties['batches_from_start'] = batch_ctr\n",
    "        yield properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-bundle",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_facts(net, nps):\n",
    "    rv = {'shorthand': net.shorthand,\n",
    "          'ksv': nps.store(net.state_vector()),\n",
    "          'loss': net.losses([training_batch])[0],\n",
    "          'head': True,\n",
    "         }\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "canadian-pendant",
   "metadata": {},
   "source": [
    "## Build the runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-feedback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_starting_entry(driver, net, nps, get_starting_facts, q_add_start):\n",
    "    starting_facts = get_starting_facts(net, nps)\n",
    "    tj.query_write(driver, q_add_start, **starting_facts)\n",
    "    return starting_facts['ksv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moved-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_by_one(driver, net, ksv, nps, observations, add_subsequent):\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(add_subsequent, observations, net)\n",
    "        print(f\"loss {observations['end_loss']}\")\n",
    "        return observations['ksv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-pittsburgh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_it(cx, driver, nps):\n",
    "    net = cx['net']\n",
    "    add_start = cx['add_net_start_to_graph']\n",
    "    add_subsequent = cx['add_net_subsequent_to_graph']\n",
    "    get_starting_facts = cx['get_starting_facts']\n",
    "    trainer = cx['trainer']\n",
    "\n",
    "    with driver.session() as session:\n",
    "        starting_facts = get_starting_facts(net, nps)\n",
    "        starting_facts['parameters_unikey'] = cx['parameters_unikey']\n",
    "        add_start(driver, starting_facts)\n",
    "        prior_ksv = starting_facts['ksv']\n",
    "        for observations in trainer(net, nps):\n",
    "            observations['prior_ksv'] = prior_ksv\n",
    "            prior_ksv = observations['ksv']\n",
    "            add_subsequent(driver, observations)\n",
    "            print(f\"loss {observations['end_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-mills",
   "metadata": {},
   "source": [
    "* At this point, all the code we need to have in the procedure has been prepared and placed in `code_strings`. It is also in the current notebook context and we can test it here too.\n",
    "* Some run-specific parameters will be placed in the Parameters nodes created by the methods below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-therapy",
   "metadata": {},
   "source": [
    "# Create the Experiment -> Procedure -> Parameters\n",
    "Create an experiment, add a procedure, add parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-seller",
   "metadata": {},
   "source": [
    "## Methods to create/merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-links",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_an_experiment(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "CREATE (e:Experiment {name: $experiment_name,\n",
    "                    unikey: $experiment_unikey,\n",
    "                        ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brief-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_procedure(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {unikey: $experiment_unikey})\n",
    "CREATE (e)-[:includes]->\n",
    "(:Procedure {name: $procedure_name,\n",
    "           unikey: $procedure_unikey,\n",
    "     code_strings: $code_strings,\n",
    "               ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters_to_experiment_procedure(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (proc:Procedure {unikey: $procedure_unikey})\n",
    "CREATE (proc)-[:incorporates]->\n",
    "(par:Parameters {unikey: $parameters_unikey,\n",
    "                   name: $parameters_name,\n",
    "           code_strings: $code_strings,\n",
    "                  trial: $trial,\n",
    "                     ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-merit",
   "metadata": {},
   "source": [
    "## Methods to acquire work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-suffering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_key_from_name(driver, **kwargs):\n",
    "    q=\"\"\"\n",
    "MATCH (e:Experiment {name: $name})\n",
    "RETURN e.unikey as unikey\n",
    "\"\"\"\n",
    "    records = nj.query_read_return_list(driver, q, **kwargs)\n",
    "    assert len(records) == 1\n",
    "    return records[0]['unikey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-diana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procedure_names_keys_from_experiment_key(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (:Experiment {unikey: $key})\n",
    "-[:includes]->\n",
    "(proc:Procedure)\n",
    "RETURN proc.name as name, proc.unikey as key\n",
    "\"\"\"\n",
    "    return [(r['name'], r['key']) for r in nj.query_read_yield(driver, q, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-elements",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unstarted_parameters_of_procedure(driver, **kwargs):\n",
    "    q=\"\"\"\n",
    "MATCH (:Procedure {unikey: $procedure_unikey})\n",
    "-[:incorporates]->\n",
    "(par:Parameters)\n",
    "WHERE NOT (par)-[:configures]->(:net)\n",
    "RETURN par.unikey as unikey\n",
    "\"\"\"\n",
    "    return [r['unikey'] for r in nj.query_read_yield(driver, q, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_strings_of_experiment_procedure_parameters(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {unikey: $experiment_unikey})\n",
    "-[:includes]->\n",
    "(proc:Procedure {unikey: $procedure_unikey})\n",
    "-[:incorporates]->\n",
    "(par:Parameters {unikey: $parameters_unikey})\n",
    "RETURN proc.code_strings, par.code_strings\n",
    "\"\"\"\n",
    "    records = nj.query_read_return_list(driver, q, **kwargs)\n",
    "    assert len(records) == 1\n",
    "    r = records[0]\n",
    "    #print(f\"r['proc.code_strings'] = {r['proc.code_strings']}\")\n",
    "    #print(f\"r['par.code_strings'] = {r['par.code_strings']}\")\n",
    "    return r['proc.code_strings'] + r['par.code_strings']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-august",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-attack",
   "metadata": {},
   "source": [
    "## Switches on what to set up now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-recipient",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_experiment = True\n",
    "setup_procedure = True\n",
    "setup_parameters = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-italian",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 't2'\n",
    "experiment_unikey = secrets.token_urlsafe(16)\n",
    "procedure_name = 'Train ADCs'\n",
    "procedure_unikey = secrets.token_urlsafe(16)\n",
    "parameters = defaultdict(dict)\n",
    "parameters['go medium']['code_strings'] = ['net.eps = 0.1']\n",
    "parameters['go medium']['trials'] = 3\n",
    "parameters['go hard']['code_strings'] = ['net.eps = 1.0']\n",
    "parameters['go hard']['trials'] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-corrections",
   "metadata": {},
   "source": [
    "## Do setups according to the switches above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-employment",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_experiment:\n",
    "    create_an_experiment(driver,\n",
    "        experiment_name=experiment_name,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "violent-beijing",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_procedure:\n",
    "    create_a_procedure(driver,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "        procedure_name=procedure_name,\n",
    "        procedure_unikey=procedure_unikey,\n",
    "        code_strings=code_strings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-teddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_parameters:\n",
    "    for name, params in parameters.items():\n",
    "        for i in range(params['trials']):\n",
    "            parameters_unikey = secrets.token_urlsafe(16)\n",
    "            code_strings = [s for s in params['code_strings']]\n",
    "            code_strings.append(f\"parameters_unikey = '{parameters_unikey}'\")\n",
    "            #print(i, code_strings)\n",
    "            create_parameters_to_experiment_procedure(driver,\n",
    "                procedure_unikey=procedure_unikey,\n",
    "                parameters_name=f\"{name} {i}\",\n",
    "                parameters_unikey=parameters_unikey,\n",
    "                code_strings=code_strings,\n",
    "                trial=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lightweight-trainer",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-glenn",
   "metadata": {},
   "source": [
    "# Here the experiment is set up in the graph database\n",
    "\n",
    "We could:\n",
    "* Run it locally here\n",
    "* Run it from the code strings we have stored here\n",
    "* Run it like the bot would, by getting the code from the database\n",
    "* Launch the bot against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-trigger",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'like bot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'local':\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    run_it(globals(), driver, nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooked-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'code_strings':\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    cx = {}\n",
    "    for s in code_strings:\n",
    "        exec(s, cx)\n",
    "    cx['run_it'](cx, driver, nps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-origin",
   "metadata": {},
   "source": [
    "## Find work and do it\n",
    "As the bot would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-settle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_strings_from_db(driver, experiment_name, procedure_name):\n",
    "    experiment_unikey = get_experiment_key_from_name(driver, name=experiment_name)\n",
    "    #print(experiment_unikey)\n",
    "    procedures = dict(get_procedure_names_keys_from_experiment_key(driver, key=experiment_unikey))\n",
    "    procedure_unikey = procedures[procedure_name]\n",
    "    #print(procedure_unikey)\n",
    "    unstarted_parameters = get_unstarted_parameters_of_procedure(driver, procedure_unikey=procedure_unikey)\n",
    "    parameters_unikey = unstarted_parameters[0]\n",
    "    #print(parameters_unikey)\n",
    "    code_strings_from_db = get_code_strings_of_experiment_procedure_parameters(driver,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "        procedure_unikey=procedure_unikey,\n",
    "        parameters_unikey=parameters_unikey)\n",
    "    return code_strings_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now_run_it(driver, code_strings):\n",
    "    cx = {}\n",
    "    for s in code_strings:\n",
    "        exec(s, cx)\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    cx['run_it'](cx, driver, nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'like bot':\n",
    "    code_strings = get_code_strings_from_db(driver, 't2', 'Train ADCs')\n",
    "    now_run_it(driver, code_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'bot':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-prisoner",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-climb",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"stop here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    experiment_unikey = get_experiment_key_from_name(driver, name=experiment_name)\n",
    "    print(experiment_unikey)\n",
    "    procedures = dict(get_procedure_names_keys_from_experiment_key(driver, key=experiment_unikey))\n",
    "    procedure_unikey = procedures[procedure_name]\n",
    "    unstarted_parameters = get_unstarted_parameters_of_procedure(driver, procedure_unikey=procedure_unikey)\n",
    "    parameters_unikey = unstarted_parameters[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings_from_db = get_code_strings_from_db(driver, 't2', 'Train ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "russian-messenger",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('\\n\\n/' + '*'*80 + '/\\n').join(code_strings_from_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_code_strings_from_db(driver, 't2', 'Train ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('\\n\\n/' + '*'*80 + '/\\n').join(code_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-christian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
