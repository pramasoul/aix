{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prime-charge",
   "metadata": {},
   "source": [
    "# Graph Experiment 2: Experiment Preparation\n",
    "Set up experiments for the bots to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-temple",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developing-ownership",
   "metadata": {},
   "source": [
    "## Capture code as strings\n",
    "We collect code from chosen cells as strings, and place them in nodes in the graph. The code is intended to be sufficient to reproduce the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-sapphire",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nnbench import NetMaker, NNMEG\n",
    "import secrets\n",
    "import time\n",
    "import tools.neotools as nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mediterranean-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2]) # Grab the cell above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-gates",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lucky-clearing",
   "metadata": {},
   "source": [
    "## Connecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-investigator",
   "metadata": {},
   "source": [
    "Need to get the `gpu-jupyter` and the `neo4j` docker containers connected. If run bare, something like:\n",
    "\n",
    "    docker network connect gpu-jupyter_default gpu-jupyter \n",
    "    docker network connect gpu-jupyter_default neo4j\n",
    "    docker network inspect gpu-jupyter_default \n",
    "    \n",
    "Docker has better ways than this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-probability",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = neo4j.GraphDatabase.driver(\"neo4j://172.19.0.2:7687\", auth=(\"neo4j\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.verify_connectivity()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-pricing",
   "metadata": {},
   "source": [
    "# The graph database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-easter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG, display\n",
    "display(SVG('ml graphdb structure r2.svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlike-rebel",
   "metadata": {},
   "source": [
    "# Prepare code for later `eval`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-hungary",
   "metadata": {},
   "source": [
    "## Create the net we will train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-moral",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnm = NetMaker(NNMEG)\n",
    "net = mnm('1x8tx8tx3tx3t')\n",
    "\n",
    "def adc(input):\n",
    "    m = max(0, min(7, int(8*input)))\n",
    "    return np.array([(m>>2)&1, (m>>1)&1, m&1]) * 2 - 1\n",
    "\n",
    "vadc = lambda v: np.array([adc(p) for p in v])\n",
    "\n",
    "x = np.arange(0, 1, 1.0/(8*8)).reshape(-1,1) # 8 points in each output region\n",
    "training_batch = (x, vadc(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arabic-gentleman",
   "metadata": {},
   "source": [
    "## First net node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_net_start_to_graph(driver, facts):\n",
    "    q = \"\"\"\n",
    "MATCH (par:Parameters {unikey: $parameters_unikey})\n",
    "CREATE (par)-[:configures]->(:net \n",
    "            {shorthand: $shorthand,\n",
    "                   ksv: $ksv,\n",
    "                  loss: $loss,\n",
    "                    ts: timestamp(),\n",
    "                  head: $head,\n",
    "    batches_from_start: 0})\n",
    "\"\"\"\n",
    "\n",
    "    nj.query_write(driver, q, **facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-alcohol",
   "metadata": {},
   "source": [
    "## Trained net nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floral-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_net_subsequent_to_graph(driver, facts):\n",
    "    q = \"\"\"\n",
    "MATCH (a:net {ksv: $prior_ksv})\n",
    "MERGE (a)-[:LEARNED\n",
    "         {batch_points: $batch_points,\n",
    "                  etas: $etas,\n",
    "    eta_change_batches: $eta_change_batches,\n",
    "  batches_this_segment: $batches_this_segment,\n",
    "                losses: $loss,\n",
    "            loss_steps: $loss_step,\n",
    "           traj_L2_sqs: $traj_L2_sq,\n",
    "   traj_cos_sq_signeds: $traj_cos_sq_signed,\n",
    "                    ts: timestamp()}]->\n",
    "(b:net\n",
    "          {shorthand: $shorthand,\n",
    "                 ksv: $ksv,\n",
    "                loss: $end_loss,\n",
    "                  ts: timestamp(),\n",
    "  batches_from_start: $batches_from_start})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **facts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-concept",
   "metadata": {},
   "source": [
    "## Train, recording trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net_an_increment(net, nps, properties):\n",
    "    loss = net.losses([training_batch])[0]\n",
    "    batch_ctr = 0\n",
    "    while loss > 1e-3:\n",
    "        batch_ctr_at_seg_start = batch_ctr\n",
    "        losses = []\n",
    "        etas = []\n",
    "        deltas = []\n",
    "        prior_loss = loss\n",
    "        while loss / prior_loss > 0.7071 and len(deltas) < 100:\n",
    "            if not etas or net.eta != etas[-1][1]:\n",
    "                etas.append([batch_ctr, net.eta])\n",
    "            loss = net.learn([training_batch])\n",
    "            if batch_ctr < 100 or batch_ctr % 100 == 0:\n",
    "                losses.append([batch_ctr, loss])\n",
    "                deltas.append([batch_ctr, net.deltas()])\n",
    "            batch_ctr += 1\n",
    "        #if losses[-1][0] < (batch_ctr-1):\n",
    "        #    losses.append([batch_ctr, loss])\n",
    "        if not deltas or deltas[-1][0] < (batch_ctr-1):\n",
    "            deltas.append((batch_ctr, net.deltas()))\n",
    "        properties = dict(zip(deltas[0][1]._fields, map(list, (zip(*(v[1] for v in deltas))))))\n",
    "        #properties = {}\n",
    "        properties['batch_points'] = [v[0] for v in deltas]\n",
    "        #properties['etas'] = etas\n",
    "        properties['etas'], properties['eta_change_batches'] = (list(v) for v in zip(*etas))\n",
    "        properties['batches_this_segment'] = batch_ctr - batch_ctr_at_seg_start\n",
    "        properties['ts'] = time.time()\n",
    "        properties['shorthand'] = net.shorthand\n",
    "        properties['ksv'] = nps.store(net.state_vector())\n",
    "        properties['end_loss'] = net.losses([training_batch])[0]\n",
    "        properties['experiment'] = 'ADC'\n",
    "        yield properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exact-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(net, nps):\n",
    "    loss = net.losses([training_batch])[0]\n",
    "    batch_ctr = 0\n",
    "    while loss > 1e-3:\n",
    "        batch_ctr_at_seg_start = batch_ctr\n",
    "        losses = []\n",
    "        etas = []\n",
    "        deltas = []\n",
    "        prior_loss = loss\n",
    "        while loss / prior_loss > 0.7071 and len(deltas) < 100:\n",
    "            if not etas or net.eta != etas[-1][1]:\n",
    "                etas.append([batch_ctr, net.eta])\n",
    "            loss = net.learn([training_batch])\n",
    "            if batch_ctr < 100 or batch_ctr % 100 == 0:\n",
    "                losses.append([batch_ctr, loss])\n",
    "                deltas.append([batch_ctr, net.deltas()])\n",
    "            batch_ctr += 1\n",
    "        #if losses[-1][0] < (batch_ctr-1):\n",
    "        #    losses.append([batch_ctr, loss])\n",
    "        if not deltas or deltas[-1][0] < (batch_ctr-1):\n",
    "            deltas.append((batch_ctr, net.deltas()))\n",
    "        properties = dict(zip(deltas[0][1]._fields, map(list, (zip(*(v[1] for v in deltas))))))\n",
    "        #properties = {}\n",
    "        properties['batch_points'] = [v[0] for v in deltas]\n",
    "        #properties['etas'] = etas\n",
    "        properties['etas'], properties['eta_change_batches'] = (list(v) for v in zip(*etas))\n",
    "        properties['batches_this_segment'] = batch_ctr - batch_ctr_at_seg_start\n",
    "        properties['ts'] = time.time()\n",
    "        properties['shorthand'] = net.shorthand\n",
    "        properties['ksv'] = nps.store(net.state_vector())\n",
    "        properties['end_loss'] = net.losses([training_batch])[0]\n",
    "        properties['batches_from_start'] = batch_ctr\n",
    "        yield properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-ceramic",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-avenue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_facts(net, nps):\n",
    "    rv = {'shorthand': net.shorthand,\n",
    "          'ksv': nps.store(net.state_vector()),\n",
    "          'loss': net.losses([training_batch])[0],\n",
    "          'head': True,\n",
    "         }\n",
    "    return rv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-florence",
   "metadata": {},
   "source": [
    "## Build the runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-thumb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_starting_entry(driver, net, nps, get_starting_facts, q_add_start):\n",
    "    starting_facts = get_starting_facts(net, nps)\n",
    "    tj.query_write(driver, q_add_start, **starting_facts)\n",
    "    return starting_facts['ksv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_by_one(driver, net, ksv, nps, observations, add_subsequent):\n",
    "    with driver.session() as session:\n",
    "        session.write_transaction(add_subsequent, observations, net)\n",
    "        print(f\"loss {observations['end_loss']}\")\n",
    "        return observations['ksv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fewer-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-hughes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_it(cx, driver, nps):\n",
    "    net = cx['net']\n",
    "    add_start = cx['add_net_start_to_graph']\n",
    "    add_subsequent = cx['add_net_subsequent_to_graph']\n",
    "    get_starting_facts = cx['get_starting_facts']\n",
    "    trainer = cx['trainer']\n",
    "\n",
    "    with driver.session() as session:\n",
    "        starting_facts = get_starting_facts(net, nps)\n",
    "        starting_facts['parameters_unikey'] = cx['parameters_unikey']\n",
    "        add_start(driver, starting_facts)\n",
    "        prior_ksv = starting_facts['ksv']\n",
    "        for observations in trainer(net, nps):\n",
    "            observations['prior_ksv'] = prior_ksv\n",
    "            prior_ksv = observations['ksv']\n",
    "            add_subsequent(driver, observations)\n",
    "            print(f\"loss {observations['end_loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-fleece",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings.append(In[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-saver",
   "metadata": {},
   "source": [
    "* At this point, all the code we need to have in the procedure has been prepared and placed in `code_strings`. It is also in the current notebook context and we can test it here too.\n",
    "* Some run-specific parameters will be placed in the Parameters nodes created by the methods below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposite-person",
   "metadata": {},
   "source": [
    "# Create the Experiment -> Procedure -> Parameters\n",
    "Create an experiment, add a procedure, add parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-queen",
   "metadata": {},
   "source": [
    "## Methods to create/merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_an_experiment(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "CREATE (e:Experiment {name: $experiment_name,\n",
    "                    unikey: $experiment_unikey,\n",
    "                        ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yellow-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_a_procedure(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {unikey: $experiment_unikey})\n",
    "CREATE (e)-[:includes]->\n",
    "(:Procedure {name: $procedure_name,\n",
    "           unikey: $procedure_unikey,\n",
    "     code_strings: $code_strings,\n",
    "               ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_parameters_to_experiment_procedure(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (proc:Procedure {unikey: $procedure_unikey})\n",
    "CREATE (proc)-[:incorporates]->\n",
    "(par:Parameters {unikey: $parameters_unikey,\n",
    "                   name: $parameters_name,\n",
    "           code_strings: $code_strings,\n",
    "                  trial: $trial,\n",
    "                     ts: timestamp()})\n",
    "\"\"\"\n",
    "    nj.query_write(driver, q, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-decrease",
   "metadata": {},
   "source": [
    "## Methods to acquire work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experiment_key_from_name(driver, **kwargs):\n",
    "    q=\"\"\"\n",
    "MATCH (e:Experiment {name: $name})\n",
    "RETURN e.unikey as unikey\n",
    "\"\"\"\n",
    "    records = nj.query_read_return_list(driver, q, **kwargs)\n",
    "    assert len(records) == 1\n",
    "    return records[0]['unikey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procedure_names_keys_from_experiment_key(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (:Experiment {unikey: $key})\n",
    "-[:includes]->\n",
    "(proc:Procedure)\n",
    "RETURN proc.name as name, proc.unikey as key\n",
    "\"\"\"\n",
    "    return [(r['name'], r['key']) for r in nj.query_read_yield(driver, q, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unstarted_parameters_of_procedure(driver, **kwargs):\n",
    "    q=\"\"\"\n",
    "MATCH (:Procedure {unikey: $procedure_unikey})\n",
    "-[:incorporates]->\n",
    "(par:Parameters)\n",
    "WHERE NOT (par)-[:configures]->(:net)\n",
    "RETURN par.unikey as unikey\n",
    "\"\"\"\n",
    "    return [r['unikey'] for r in nj.query_read_yield(driver, q, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-prompt",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_strings_of_experiment_procedure_parameters(driver, **kwargs):\n",
    "    q = \"\"\"\n",
    "MATCH (e:Experiment {unikey: $experiment_unikey})\n",
    "-[:includes]->\n",
    "(proc:Procedure {unikey: $procedure_unikey})\n",
    "-[:incorporates]->\n",
    "(par:Parameters {unikey: $parameters_unikey})\n",
    "RETURN proc.code_strings, par.code_strings\n",
    "\"\"\"\n",
    "    records = nj.query_read_return_list(driver, q, **kwargs)\n",
    "    assert len(records) == 1\n",
    "    r = records[0]\n",
    "    #print(f\"r['proc.code_strings'] = {r['proc.code_strings']}\")\n",
    "    #print(f\"r['par.code_strings'] = {r['par.code_strings']}\")\n",
    "    return r['proc.code_strings'] + r['par.code_strings']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-blake",
   "metadata": {},
   "source": [
    "# Experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooperative-genre",
   "metadata": {},
   "source": [
    "## Switches on what to set up now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_experiment = True\n",
    "setup_procedure = True\n",
    "setup_parameters = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-sister",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mounted-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 't2'\n",
    "experiment_unikey = secrets.token_urlsafe(16)\n",
    "procedure_name = 'Train ADCs'\n",
    "procedure_unikey = secrets.token_urlsafe(16)\n",
    "parameters = defaultdict(dict)\n",
    "parameters['go medium']['code_strings'] = ['net.eps = 0.1']\n",
    "parameters['go medium']['trials'] = 3\n",
    "parameters['go hard']['code_strings'] = ['net.eps = 1.0']\n",
    "parameters['go hard']['trials'] = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completed-aviation",
   "metadata": {},
   "source": [
    "## Do setups according to the switches above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_experiment:\n",
    "    create_an_experiment(driver,\n",
    "        experiment_name=experiment_name,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_procedure:\n",
    "    create_a_procedure(driver,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "        procedure_name=procedure_name,\n",
    "        procedure_unikey=procedure_unikey,\n",
    "        code_strings=code_strings,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setup_parameters:\n",
    "    for name, params in parameters.items():\n",
    "        for i in range(params['trials']):\n",
    "            parameters_unikey = secrets.token_urlsafe(16)\n",
    "            code_strings = [s for s in params['code_strings']]\n",
    "            code_strings.append(f\"parameters_unikey = '{parameters_unikey}'\")\n",
    "            #print(i, code_strings)\n",
    "            create_parameters_to_experiment_procedure(driver,\n",
    "                procedure_unikey=procedure_unikey,\n",
    "                parameters_name=f\"{name} {i}\",\n",
    "                parameters_unikey=parameters_unikey,\n",
    "                code_strings=code_strings,\n",
    "                trial=i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-methodology",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-olive",
   "metadata": {},
   "source": [
    "# Here the experiment is set up in the graph database\n",
    "\n",
    "We could:\n",
    "* Run it locally here\n",
    "* Run it from the code strings we have stored here\n",
    "* Run it like the bot would, by getting the code from the database\n",
    "* Launch the bot against it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-liquid",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = 'like bot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'local':\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    run_it(globals(), driver, nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "junior-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'code_strings':\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    cx = {}\n",
    "    for s in code_strings:\n",
    "        exec(s, cx)\n",
    "    cx['run_it'](cx, driver, nps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-catch",
   "metadata": {},
   "source": [
    "## Find work and do it\n",
    "As the bot would"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-excitement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code_strings_from_db(driver, experiment_name, procedure_name):\n",
    "    experiment_unikey = get_experiment_key_from_name(driver, name=experiment_name)\n",
    "    #print(experiment_unikey)\n",
    "    procedures = dict(get_procedure_names_keys_from_experiment_key(driver, key=experiment_unikey))\n",
    "    procedure_unikey = procedures[procedure_name]\n",
    "    #print(procedure_unikey)\n",
    "    unstarted_parameters = get_unstarted_parameters_of_procedure(driver, procedure_unikey=procedure_unikey)\n",
    "    parameters_unikey = unstarted_parameters[0]\n",
    "    #print(parameters_unikey)\n",
    "    code_strings_from_db = get_code_strings_of_experiment_procedure_parameters(driver,\n",
    "        experiment_unikey=experiment_unikey,\n",
    "        procedure_unikey=procedure_unikey,\n",
    "        parameters_unikey=parameters_unikey)\n",
    "    return code_strings_from_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def now_run_it(driver, code_strings):\n",
    "    cx = {}\n",
    "    for s in code_strings:\n",
    "        exec(s, cx)\n",
    "    nps = nj.NumpyStore(driver)\n",
    "    cx['run_it'](cx, driver, nps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'like bot':\n",
    "    code_strings = get_code_strings_from_db(driver, 't2', 'Train ADCs')\n",
    "    now_run_it(driver, code_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run == 'bot':\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-pressing",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respective-rings",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"stop here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "related-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    experiment_unikey = get_experiment_key_from_name(driver, name=experiment_name)\n",
    "    print(experiment_unikey)\n",
    "    procedures = dict(get_procedure_names_keys_from_experiment_key(driver, key=experiment_unikey))\n",
    "    procedure_unikey = procedures[procedure_name]\n",
    "    unstarted_parameters = get_unstarted_parameters_of_procedure(driver, procedure_unikey=procedure_unikey)\n",
    "    parameters_unikey = unstarted_parameters[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_strings_from_db = get_code_strings_from_db(driver, 't2', 'Train ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('\\n\\n/' + '*'*80 + '/\\n').join(code_strings_from_db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_code_strings_from_db(driver, 't2', 'Train ADCs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(('\\n\\n/' + '*'*80 + '/\\n').join(code_strings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-greek",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
